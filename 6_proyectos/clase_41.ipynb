{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9LRMV+whk8ks4pVW+YCzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/sic_ai_2025_sept/blob/main/6_proyectos/clase_41.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversación con grok para ejercicio de detección de victimas y victimarios\n",
        "\n",
        "https://grok.com/share/bGVnYWN5_c75023c4-13a0-493f-a185-82dadf1d0c80\n",
        "\n",
        "\n",
        "¡Entendido! Quieres ejemplos de código usando MoveNet para procesar videos y detectar poses, lo cual es útil para identificar agresores y víctimas en tu caso de detección de crímenes en videos. MoveNet es un modelo ligero de estimación de poses de Google, ideal para analizar skeletons (puntos clave del cuerpo) en tiempo real, y puede ayudarte a inferir roles basados en movimientos (ej. un agresor levantando un brazo para golpear, una víctima retrocediendo). A continuación, te doy dos ejemplos prácticos en Python usando MoveNet: uno para procesar un solo frame (imagen) y otro para videos, integrando detección de personas y análisis básico de roles.\n",
        "\n",
        "### Prerrequisitos\n",
        "- **Instalaciones**:\n",
        "  ```bash\n",
        "  pip install tensorflow tensorflow-hub opencv-python numpy\n",
        "  ```\n",
        "- **Hardware**: MoveNet es ligero, funciona en CPU, pero GPU acelera (Colab es buena opción).\n",
        "- **Modelo**: Usaremos MoveNet.SinglePose (versión \"Lightning\" para rapidez o \"Thunder\" para precisión). Disponible en TensorFlow Hub.\n",
        "\n",
        "### Ejemplo 1: Detección de Poses en una Imagen\n",
        "Este código detecta puntos clave (keypoints) en una imagen estática, útil para entender cómo MoveNet procesa una persona.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Carga MoveNet desde TensorFlow Hub (Lightning para rapidez)\n",
        "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = model.signatures['serving_default']\n",
        "\n",
        "# Preprocesa imagen\n",
        "def preprocess_image(image):\n",
        "    img = cv2.resize(image, (192, 192))  # MoveNet Lightning usa 192x192\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)  # Añade batch dimension\n",
        "    return img\n",
        "\n",
        "# Detecta poses\n",
        "def detect_pose(image):\n",
        "    input_image = preprocess_image(image)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [persona, keypoints, (y, x, confianza)]\n",
        "    return keypoints\n",
        "\n",
        "# Visualiza keypoints\n",
        "def draw_keypoints(image, keypoints, conf_threshold=0.3):\n",
        "    height, width = image.shape[:2]\n",
        "    for keypoint in keypoints:\n",
        "        y, x, confidence = keypoint\n",
        "        if confidence > conf_threshold:\n",
        "            x = int(x * width)\n",
        "            y = int(y * height)\n",
        "            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)  # Dibuja punto verde\n",
        "    return image\n",
        "\n",
        "# Carga y procesa imagen\n",
        "image_path = 'tu_imagen.jpg'  # Reemplaza con tu imagen\n",
        "image = cv2.imread(image_path)\n",
        "keypoints = detect_pose(image)\n",
        "image_with_keypoints = draw_keypoints(image.copy(), keypoints)\n",
        "\n",
        "# Guarda o muestra resultado\n",
        "cv2.imwrite('output_image.jpg', image_with_keypoints)\n",
        "cv2.imshow('Pose Detection', image_with_keypoints)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "```\n",
        "\n",
        "**Explicación**:\n",
        "- Carga MoveNet desde TensorFlow Hub.\n",
        "- Procesa la imagen (resize a 192x192, formato requerido por MoveNet).\n",
        "- Extrae 17 keypoints (nariz, hombros, codos, muñecas, etc.) con coordenadas (y, x) y confianza.\n",
        "- Dibuja puntos en la imagen si la confianza es >0.3.\n",
        "- Útil para pruebas iniciales. Para roles (agresor/víctima), analiza keypoints como distancia entre manos y torso de otra persona.\n",
        "\n",
        "### Ejemplo 2: Detección de Poses en Video con Análisis de Roles\n",
        "Este código procesa un video, detecta personas con YOLOv8 (para identificar múltiples actores), aplica MoveNet para estimar poses y hace un análisis básico de movimientos para inferir agresor/víctima.\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO  # Para YOLOv8\n",
        "\n",
        "# Carga modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')  # Modelo YOLOv8 preentrenado (instala ultralytics: pip install ultralytics)\n",
        "\n",
        "# Preprocesa frame para MoveNet\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Detecta poses\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [persona, keypoints, (y, x, conf)]\n",
        "    return keypoints\n",
        "\n",
        "# Analiza movimiento para roles (heurística simple)\n",
        "def analyze_roles(keypoints_list, person_boxes):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        # Ejemplo: Si mano derecha (keypoint 10) está alta y cerca de otra persona, posible agresor\n",
        "        right_wrist = keypoints[10]  # [y, x, conf]\n",
        "        if right_wrist[2] > 0.3:  # Confianza suficiente\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:  # Evita compararse consigo mismo\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    if abs(wrist_x * 192 - ox) < 50 and wrist_y * 192 < oy:  # Mano cerca y alta\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'victima'))\n",
        "                        return roles\n",
        "    return roles\n",
        "\n",
        "# Procesa video\n",
        "def process_video(video_path, output_path='output_video.mp4'):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detecta personas con YOLOv8\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if box.cls == 0:  # 0 es 'person' en COCO\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Aplica MoveNet a cada persona\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[y:y+h, x:x+w]\n",
        "            if person_crop.size > 0:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "\n",
        "        # Analiza roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes)\n",
        "\n",
        "        # Dibuja resultados\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            cv2.putText(frame, role, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "            # Dibuja keypoints\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:  # Confianza\n",
        "                    kx, ky = int(kp[1] * w + x), int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 5, (255, 0, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "# Uso\n",
        "process_video('tu_video.mp4', 'output_video.mp4')\n",
        "```\n",
        "\n",
        "**Explicación**:\n",
        "- **YOLOv8**: Detecta personas y extrae bounding boxes.\n",
        "- **MoveNet**: Estima poses (17 keypoints) para cada persona detectada.\n",
        "- **Análisis de Roles**: Heurística simple: si una mano está alta y cerca de otra persona, se etiqueta como \"agresor\". La otra como \"víctima\". Puedes mejorar esto con:\n",
        "  - Modelos ST-GCN para analizar secuencias de poses.\n",
        "  - Detección de velocidad (optical flow) para confirmar movimientos agresivos.\n",
        "- **Salida**: Video con bounding boxes, keypoints y etiquetas de roles.\n",
        "\n",
        "### 5. **Mejoras y Notas**\n",
        "- **Precisión de Roles**: La heurística es básica. Para mejor precisión:\n",
        "  - Entrena un modelo (ej. ST-GCN o SlowFast) con datasets como RWF-2000, anotando agresores/víctimas.\n",
        "  - Usa optical flow (cv2.calcOpticalFlowFarneback) para detectar dirección/velocidad de movimientos.\n",
        "- **Escalabilidad**: MoveNet es rápido (10-20 FPS en CPU). Para tiempo real, optimiza con TensorRT.\n",
        "- **Datos**: Fine-tunea con datasets como SCVD o UCF-Crime, anotando roles. Herramientas como CVAT ayudan.\n",
        "- **Ética**: Anonimiza rostros (ej. con Mediapipe Face Detection) para privacidad.\n",
        "- **Audio**: Si los videos tienen audio, combina con diarización (Librosa o pyannote.audio) para contexto (ej. gritos).\n",
        "\n",
        "### 6. **Siguientes Pasos**\n",
        "- **Fine-Tuning**: Anota un subconjunto de tus videos con CVAT y entrena un modelo custom (ej. en Kinetics o RWF-2000).\n",
        "- **Modelos Avanzados**: Explora VideoMAE o TimeSformer para acción y roles end-to-end.\n",
        "- **Código Adicional**: Si quieres integrar optical flow o ST-GCN, puedo dar otro snippet. ¿Detalles sobre tus videos (duración, resolución, tipo de crímenes)? ¿O prefieres enfocarte en algo específico (ej. datasets, entrenamiento)? ¡Dime!"
      ],
      "metadata": {
        "id": "zvPg5-ijKTWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-hub opencv-python-headless ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M6OzfcRKkPO",
        "outputId": "bd3f9c80-3c48-407d-cc32-69e54b54aed2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.225-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading ultralytics-8.3.225-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.225 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYwaa6ryKC2t",
        "outputId": "c8f96af7-9ebb-49e4-80a1-e49f2f25dc81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 316.7MB/s 0.0s\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO  # Para YOLOv8\n",
        "\n",
        "# Carga modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')  # Modelo YOLOv8 preentrenado (instala ultralytics: pip install ultralytics)\n",
        "\n",
        "# Preprocesa frame para MoveNet\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Detecta poses\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [persona, keypoints, (y, x, conf)]\n",
        "    return keypoints\n",
        "\n",
        "# Analiza movimiento para roles (heurística simple)\n",
        "def analyze_roles(keypoints_list, person_boxes):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        # Ejemplo: Si mano derecha (keypoint 10) está alta y cerca de otra persona, posible agresor\n",
        "        right_wrist = keypoints[10]  # [y, x, conf]\n",
        "        if right_wrist[2] > 0.3:  # Confianza suficiente\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:  # Evita compararse consigo mismo\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    if abs(wrist_x * 192 - ox) < 50 and wrist_y * 192 < oy:  # Mano cerca y alta\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'victima'))\n",
        "                        return roles\n",
        "    return roles\n",
        "\n",
        "# Procesa video\n",
        "def process_video(video_path, output_path='output_video.mp4'):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detecta personas con YOLOv8\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if box.cls == 0:  # 0 es 'person' en COCO\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Aplica MoveNet a cada persona\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[y:y+h, x:x+w]\n",
        "            if person_crop.size > 0:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "\n",
        "        # Analiza roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes)\n",
        "\n",
        "        # Dibuja resultados\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            cv2.putText(frame, role, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "            # Dibuja keypoints\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:  # Confianza\n",
        "                    kx, ky = int(kp[1] * w + x), int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 5, (255, 0, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "# Uso\n",
        "process_video('tu_video.mp4', 'output_video.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias\n",
        "!pip install tensorflow tensorflow-hub opencv-python-headless ultralytics\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Carga modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')  # Modelo YOLOv8 preentrenado\n",
        "\n",
        "# Preprocesa frame para MoveNet\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Detecta poses\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [persona, keypoints, (y, x, conf)]\n",
        "    return keypoints\n",
        "\n",
        "# Analiza movimiento para roles (heurística simple)\n",
        "def analyze_roles(keypoints_list, person_boxes):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        right_wrist = keypoints[10]  # [y, x, conf]\n",
        "        if right_wrist[2] > 0.3:  # Confianza suficiente\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:  # Evita compararse consigo mismo\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    if abs(wrist_x * 192 - ox) < 50 and wrist_y * 192 < oy:  # Mano cerca y alta\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'victima'))\n",
        "                        return roles\n",
        "    return roles\n",
        "\n",
        "# Calcula métricas (F1-score para roles)\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if len(y_true) == len(y_pred):\n",
        "        f1 = f1_score(y_true, y_pred, labels=['agresor', 'victima'], average='weighted')\n",
        "        return f1\n",
        "    return 0.0\n",
        "\n",
        "# Procesa video\n",
        "def process_video(video_path, output_path='output_video.mp4', ground_truth_roles=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detecta personas con YOLOv8\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if box.cls == 0:  # 0 es 'person' en COCO\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Aplica MoveNet a cada persona\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[y:y+h, x:x+w]\n",
        "            if person_crop.size > 0:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "\n",
        "        # Analiza roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes)\n",
        "        all_pred_roles.append(roles)\n",
        "\n",
        "        # Dibuja resultados\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            cv2.putText(frame, role, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx, ky = int(kp[1] * w + x), int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 5, (255, 0, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Calcula métricas si hay ground truth\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0])  # Ejemplo con un frame\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# Sube el video\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Ground truth de ejemplo (ajusta con tus datos reales)\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'victima')]  # Asumiendo 2 personas en el video\n",
        "\n",
        "# Procesa el video y descarga el resultado\n",
        "output_path = process_video(video_path, 'output_video.mp4', ground_truth_roles)\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5f18z6SiK73A",
        "outputId": "5f626f0a-c188-4ca7-b4c8-1d412b85972e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.225)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-hub) (2.19.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e93d299-776a-4b5d-8ece-09f10197c87f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e93d299-776a-4b5d-8ece-09f10197c87f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving people-detection.mp4 to people-detection.mp4\n",
            "\n",
            "0: 384x640 (no detections), 77.4ms\n",
            "Speed: 15.4ms preprocess, 77.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 3.4ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.7ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.3ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.3ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.5ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.4ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.2ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.2ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 2.4ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.4ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 3.0ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.1ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.5ms\n",
            "Speed: 2.2ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.5ms\n",
            "Speed: 2.5ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.6ms\n",
            "Speed: 2.4ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.1ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.4ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.6ms\n",
            "Speed: 2.3ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.6ms\n",
            "Speed: 2.2ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.7ms\n",
            "Speed: 2.2ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 2.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 2.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 2.8ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 3.6ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.6ms preprocess, 5.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.7ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.7ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.3ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.4ms\n",
            "Speed: 2.1ms preprocess, 5.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 2.9ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.8ms preprocess, 5.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.4ms preprocess, 5.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 2.3ms preprocess, 6.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 2.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 1.6ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.4ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.6ms\n",
            "Speed: 2.7ms preprocess, 5.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.8ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.4ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.4ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.3ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.6ms\n",
            "Speed: 2.2ms preprocess, 5.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.6ms\n",
            "Speed: 2.7ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.7ms\n",
            "Speed: 2.2ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 2.3ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.4ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 2.4ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.5ms\n",
            "Speed: 2.5ms preprocess, 5.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.4ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.9ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.2ms\n",
            "Speed: 1.8ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.7ms\n",
            "Speed: 2.6ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 2.5ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.2ms\n",
            "Speed: 2.5ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 2.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 2.7ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 2.2ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 2.7ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.5ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.8ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.3ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.9ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.4ms preprocess, 5.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.5ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 2.3ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.4ms\n",
            "Speed: 1.7ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.4ms\n",
            "Speed: 2.2ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.4ms\n",
            "Speed: 2.6ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.0ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.4ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.4ms preprocess, 5.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.5ms preprocess, 5.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.4ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.7ms\n",
            "Speed: 2.5ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.4ms\n",
            "Speed: 2.3ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 2.4ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.8ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.4ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.7ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.9ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.4ms\n",
            "Speed: 2.5ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 4.9ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 5.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.4ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.5ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.7ms\n",
            "Speed: 2.6ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.7ms preprocess, 5.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.2ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.2ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.5ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.5ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.7ms\n",
            "Speed: 2.9ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 3.0ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.7ms\n",
            "Speed: 2.4ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 2.4ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.2ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.7ms\n",
            "Speed: 2.4ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.5ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 2.9ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.5ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.7ms\n",
            "Speed: 2.1ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.3ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.6ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.7ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.8ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.7ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.9ms preprocess, 5.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.5ms\n",
            "Speed: 2.5ms preprocess, 5.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.5ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 3.1ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.6ms\n",
            "Speed: 2.5ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 4.7ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.9ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 5.6ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 3.7ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 4.0ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 4.1ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.3ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 2.4ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 4.2ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 4.2ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 3.6ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.6ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.6ms\n",
            "Speed: 4.1ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 4.0ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.6ms\n",
            "Speed: 2.4ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.8ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.8ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.7ms\n",
            "Speed: 3.8ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tv, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tv, 10.7ms\n",
            "Speed: 4.1ms preprocess, 10.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tv, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tv, 9.5ms\n",
            "Speed: 4.3ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tv, 11.1ms\n",
            "Speed: 4.0ms preprocess, 11.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 2.7ms preprocess, 11.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 2.8ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 6.3ms\n",
            "Speed: 2.8ms preprocess, 6.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 7.9ms\n",
            "Speed: 3.7ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 2.3ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.6ms\n",
            "Speed: 2.8ms preprocess, 6.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 2.4ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.4ms\n",
            "Speed: 2.4ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 2.4ms preprocess, 6.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 6.9ms\n",
            "Speed: 2.3ms preprocess, 6.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cell phone, 7.2ms\n",
            "Speed: 2.5ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 2.3ms preprocess, 6.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.1ms\n",
            "Speed: 1.6ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 2.3ms preprocess, 5.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 2.5ms preprocess, 5.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 2.4ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 3.2ms preprocess, 6.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.2ms\n",
            "Speed: 1.8ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.6ms\n",
            "Speed: 2.4ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.8ms\n",
            "Speed: 4.6ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 2.8ms preprocess, 5.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tv, 5.8ms\n",
            "Speed: 2.9ms preprocess, 5.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.2ms\n",
            "Speed: 2.6ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 2.9ms preprocess, 6.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.4ms preprocess, 5.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.9ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.3ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.2ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 2.3ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.3ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 2.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.1ms preprocess, 6.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 2.0ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.5ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 2.6ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.4ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.5ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 2.7ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.8ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.3ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 3.0ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 4.7ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 4.6ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 4.8ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 5.6ms preprocess, 17.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 2.4ms preprocess, 23.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 4.0ms preprocess, 16.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.2ms\n",
            "Speed: 4.9ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 39.7ms\n",
            "Speed: 4.9ms preprocess, 39.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 6.8ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 4.5ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 4.4ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 24.5ms\n",
            "Speed: 7.8ms preprocess, 24.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 4.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 4.8ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.1ms\n",
            "Speed: 2.5ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 4.0ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 3.0ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 3.6ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 5.7ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 3.8ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 6.6ms preprocess, 16.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 4.4ms preprocess, 17.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.9ms\n",
            "Speed: 2.9ms preprocess, 23.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.9ms\n",
            "Speed: 5.4ms preprocess, 28.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 4.9ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.4ms\n",
            "Speed: 10.5ms preprocess, 27.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.0ms\n",
            "Speed: 4.5ms preprocess, 25.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 7.0ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 4.4ms preprocess, 20.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 3.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 7.3ms preprocess, 17.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 2.7ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.6ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 3.9ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 2.5ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.5ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.5ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.6ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.7ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 2.4ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 36.0ms\n",
            "Speed: 2.5ms preprocess, 36.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 7.1ms preprocess, 21.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.1ms\n",
            "Speed: 8.8ms preprocess, 27.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 4.6ms preprocess, 20.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 5.3ms preprocess, 10.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.2ms\n",
            "Speed: 10.6ms preprocess, 25.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 7.4ms preprocess, 14.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.2ms\n",
            "Speed: 6.3ms preprocess, 22.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 40.3ms\n",
            "Speed: 10.7ms preprocess, 40.3ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 12.5ms\n",
            "Speed: 5.5ms preprocess, 12.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 32.1ms\n",
            "Speed: 4.6ms preprocess, 32.1ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 toilet, 17.8ms\n",
            "Speed: 4.2ms preprocess, 17.8ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 5.6ms preprocess, 14.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 46.1ms\n",
            "Speed: 13.4ms preprocess, 46.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.2ms\n",
            "Speed: 5.9ms preprocess, 22.2ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 7.2ms preprocess, 11.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 9.6ms preprocess, 12.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 4.0ms preprocess, 11.2ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 12.7ms preprocess, 10.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 5.1ms preprocess, 14.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 38.6ms\n",
            "Speed: 4.4ms preprocess, 38.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 4.4ms preprocess, 12.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 6.7ms preprocess, 15.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 51.0ms\n",
            "Speed: 13.2ms preprocess, 51.0ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 sports ball, 16.7ms\n",
            "Speed: 6.5ms preprocess, 16.7ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 24.8ms\n",
            "Speed: 6.9ms preprocess, 24.8ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 42.3ms\n",
            "Speed: 6.5ms preprocess, 42.3ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.3ms\n",
            "Speed: 2.9ms preprocess, 6.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.2ms\n",
            "Speed: 2.7ms preprocess, 6.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 tv, 7.3ms\n",
            "Speed: 3.4ms preprocess, 7.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.5ms\n",
            "Speed: 2.6ms preprocess, 6.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.5ms\n",
            "Speed: 2.4ms preprocess, 6.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.4ms\n",
            "Speed: 2.5ms preprocess, 6.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.9ms\n",
            "Speed: 2.7ms preprocess, 6.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.1ms\n",
            "Speed: 2.4ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 skateboard, 1 tv, 6.9ms\n",
            "Speed: 2.6ms preprocess, 6.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 skateboard, 2 tvs, 7.2ms\n",
            "Speed: 4.5ms preprocess, 7.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.4ms\n",
            "Speed: 2.3ms preprocess, 6.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 6.8ms\n",
            "Speed: 3.4ms preprocess, 6.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.3ms\n",
            "Speed: 2.3ms preprocess, 6.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.3ms\n",
            "Speed: 2.5ms preprocess, 6.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.0ms\n",
            "Speed: 1.6ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.4ms\n",
            "Speed: 1.7ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 2.8ms preprocess, 6.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 2.3ms preprocess, 7.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.7ms\n",
            "Speed: 2.5ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 3.7ms preprocess, 6.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tv, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.3ms\n",
            "Speed: 2.8ms preprocess, 6.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.6ms\n",
            "Speed: 2.3ms preprocess, 5.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.5ms\n",
            "Speed: 2.7ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 2.6ms preprocess, 6.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 2.6ms preprocess, 5.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 2.7ms preprocess, 6.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 2.7ms preprocess, 6.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.2ms\n",
            "Speed: 3.6ms preprocess, 7.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.8ms\n",
            "Speed: 2.6ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 6.1ms\n",
            "Speed: 2.4ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 2.4ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.5ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 7.1ms\n",
            "Speed: 2.4ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 7.9ms\n",
            "Speed: 3.6ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 2.5ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 2.6ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.4ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 chair, 7.3ms\n",
            "Speed: 2.9ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 2.4ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.6ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.8ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 3.5ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 3.3ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 2.6ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 3.5ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 2.6ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.7ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 3.0ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.6ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 5.3ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 3.0ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 2.4ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.1ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.6ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 4.0ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 2.5ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 2.8ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.4ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 3.5ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 2.7ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.8ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 27.1ms\n",
            "Speed: 4.2ms preprocess, 27.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.4ms\n",
            "Speed: 8.3ms preprocess, 17.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.3ms\n",
            "Speed: 2.5ms preprocess, 28.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 26.6ms\n",
            "Speed: 5.1ms preprocess, 26.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 19.2ms\n",
            "Speed: 6.1ms preprocess, 19.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.0ms\n",
            "Speed: 4.8ms preprocess, 21.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 2.7ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 3.5ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 3.2ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 3.9ms preprocess, 12.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 4.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 4.3ms preprocess, 22.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 3.3ms preprocess, 18.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 6.1ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 4.8ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 6.0ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 22.5ms\n",
            "Speed: 6.9ms preprocess, 22.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 7.6ms preprocess, 16.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 5.5ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 4.5ms preprocess, 20.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.5ms\n",
            "Speed: 4.5ms preprocess, 17.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 3.4ms preprocess, 16.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.8ms\n",
            "Speed: 8.6ms preprocess, 18.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 30.4ms\n",
            "Speed: 5.8ms preprocess, 30.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 28.2ms\n",
            "Speed: 8.9ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 24.7ms\n",
            "Speed: 6.5ms preprocess, 24.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 32.5ms\n",
            "Speed: 6.4ms preprocess, 32.5ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 5.6ms preprocess, 18.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.9ms\n",
            "Speed: 4.4ms preprocess, 18.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 4.5ms preprocess, 20.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 25.7ms\n",
            "Speed: 4.9ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 6.1ms preprocess, 23.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 21.3ms\n",
            "Speed: 6.3ms preprocess, 21.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 12.8ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 4.5ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.8ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 3.7ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.8ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 14.7ms\n",
            "Speed: 5.0ms preprocess, 14.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 12.1ms\n",
            "Speed: 5.3ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 4.1ms preprocess, 13.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 4.7ms preprocess, 11.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 4.6ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.0ms\n",
            "Speed: 4.2ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 3.1ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 2.6ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 2.3ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.8ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 4.4ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 3.4ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 5.6ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.9ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 2.8ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 4.0ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 2.9ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 2.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 3.6ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 3.0ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "F1-Score para roles: 0.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40924a57-6c57-4541-bde7-16633122b840\", \"output_video.mp4\", 4029895)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Entendido! Te proporciono un código completo para Google Colab que realiza el proceso completo: descarga el dataset \"Hockey Fight Videos\" desde Kaggle, procesa un video usando YOLOv8 para detectar personas, MoveNet para estimar poses, y asigna etiquetas de \"agresor\" y \"víctima\" basadas en una heurística simple (mano derecha alta y cerca de otra persona). También incluye métricas básicas (F1-score) y visualización de etiquetas claras en el video de salida. El código está optimizado para Colab, con instrucciones para autenticar Kaggle, descargar el dataset, procesar un video y descargar el resultado.\n",
        "\n",
        "### Características del Código\n",
        "- **Dataset**: Usa \"Hockey Fight Videos\" (https://www.kaggle.com/datasets/yassershrief/hockey-fight-vidoes), con clips de peleas y no-peleas, ideal para detectar interacciones físicas.\n",
        "- **Modelos**: YOLOv8 para detección de personas, MoveNet para poses.\n",
        "- **Etiquetado**: Asigna \"agresor\" (mano alta y cerca de otra persona) y \"víctima\" (persona cercana al movimiento agresivo). Etiquetas en rojo (agresor) y azul (víctima) en el video.\n",
        "- **Métricas**: Calcula F1-score para roles, asumiendo un ground truth de ejemplo (puedes ajustarlo con anotaciones reales).\n",
        "- **Colab**: Incluye instalación de dependencias, carga del dataset, y descarga del video procesado.\n",
        "\n",
        "### Código Completo para Colab\n",
        "```python\n",
        "# 1. Instalar dependencias\n",
        "!pip install -q tensorflow tensorflow-hub opencv-python-headless ultralytics sklearn\n",
        "!pip install -q kaggle\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# 2. Configurar Kaggle API\n",
        "print(\"Sube tu kaggle.json (descárgalo desde Kaggle > Account > Create API Token)\")\n",
        "uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 3. Descargar y descomprimir Hockey Fight Videos dataset\n",
        "!kaggle datasets download -d yassershrief/hockey-fight-vidoes\n",
        "!unzip -q hockey-fight-vidoes.zip\n",
        "\n",
        "# 4. Cargar modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')  # Modelo YOLOv8 preentrenado\n",
        "\n",
        "# 5. Preprocesar frame para MoveNet\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# 6. Detectar poses\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [persona, keypoints, (y, x, conf)]\n",
        "    return keypoints\n",
        "\n",
        "# 7. Analizar movimiento para roles (heurística: mano derecha alta y cerca)\n",
        "def analyze_roles(keypoints_list, person_boxes):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        right_wrist = keypoints[10]  # Mano derecha: [y, x, conf]\n",
        "        if right_wrist[2] > 0.3:  # Confianza suficiente\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:  # Evita compararse consigo mismo\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    if abs(wrist_x * 192 - ox) < 100 and wrist_y * 192 < oy:  # Mano alta y cerca\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'víctima'))\n",
        "                        return roles\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]  # Default si no hay detección\n",
        "\n",
        "# 8. Calcular métricas (F1-score para roles)\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if y_true and y_pred and len(y_true) == len(y_pred):\n",
        "        f1 = f1_score(y_true, y_pred, labels=['agresor', 'víctima', 'desconocido'], average='weighted')\n",
        "        return f1\n",
        "    return 0.0\n",
        "\n",
        "# 9. Procesar video\n",
        "def process_video(video_path, output_path='output_hockey.mp4', ground_truth_roles=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: No se pudo abrir el video {video_path}\")\n",
        "        return None\n",
        "    \n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    \n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "    \n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        # Reducir resolución para rapidez (opcional)\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        width, height = 640, 480\n",
        "        \n",
        "        # Detectar personas con YOLOv8\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if box.cls == 0:  # 0 es 'person' en COCO\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "        \n",
        "        # Aplicar MoveNet a cada persona\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))  # Dummy si crop falla\n",
        "        \n",
        "        # Analizar roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes)\n",
        "        all_pred_roles.append(roles)\n",
        "        \n",
        "        # Dibujar resultados\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            # Etiquetas: rojo para agresor, azul para víctima\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx, ky = int(kp[1] * w + x), int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 5, (255, 255, 0), -1)\n",
        "        \n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0:\n",
        "            print(f\"Procesados {frame_count} frames\")\n",
        "    \n",
        "    cap.release()\n",
        "    out.release()\n",
        "    \n",
        "    # Calcular métricas si hay ground truth\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "    \n",
        "    print(f\"Video procesado guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# 10. Seleccionar un video y procesar\n",
        "video_path = 'fights/fi001.mp4'  # Ajusta según el nombre exacto (verifica con !ls fights/)\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo, ajusta si tienes CSV\n",
        "output_path = process_video(video_path, 'output_hockey.mp4', ground_truth_roles)\n",
        "\n",
        "# 11. Descargar resultado\n",
        "if output_path and os.path.exists(output_path):\n",
        "    files.download(output_path)\n",
        "else:\n",
        "    print(\"Error: No se generó el video de salida\")\n",
        "```\n",
        "\n",
        "### Instrucciones para Usar\n",
        "1. **Crear Notebook en Colab**:\n",
        "   - Ve a https://colab.research.google.com/, crea un nuevo notebook.\n",
        "   - Activa GPU: Entorno de ejecución → Cambiar tipo → T4 GPU.\n",
        "\n",
        "2. **Subir kaggle.json**:\n",
        "   - Descarga tu API token desde Kaggle (Account → Create API Token).\n",
        "   - En la celda de `files.upload()`, sube `kaggle.json`.\n",
        "\n",
        "3. **Verificar Videos**:\n",
        "   - Después de descomprimir (`!unzip`), lista los videos con:\n",
        "     ```python\n",
        "     !ls fights/  # O !ls no_fights/\n",
        "     ```\n",
        "   - Actualiza `video_path = 'fights/fi001.mp4'` con un nombre real (los videos son `fi001.mp4`, `fi002.mp4`, etc.).\n",
        "\n",
        "4. **Ground Truth**:\n",
        "   - El código usa un ejemplo: `[(0, 'agresor'), (1, 'víctima')]`. Para métricas reales, anota roles con CVAT o usa el CSV del dataset (si incluye labels). Ejemplo CSV:\n",
        "     ```csv\n",
        "     frame_id,person_id,role\n",
        "     1,0,agresor\n",
        "     1,1,víctima\n",
        "     ```\n",
        "     Carga con `pandas.read_csv()` y pásalo a `ground_truth_roles`.\n",
        "\n",
        "5. **Ejecutar**:\n",
        "   - Corre todas las celdas. Descargará el dataset (~100-200 MB), procesará el video y descargará `output_hockey.mp4`.\n",
        "   - Verás etiquetas: **rojo** para \"agresor\", **azul** para \"víctima\", gris para \"desconocido\".\n",
        "\n",
        "### Detalles del Código\n",
        "- **Etiquetado Visual**: Usa colores distintos (rojo/azul) para diferenciar agresor/víctima en el video, con bounding boxes verdes y keypoints amarillos.\n",
        "- **Heurística de Roles**: Detecta \"agresor\" si la mano derecha (keypoint 10) está alta (y baja en coordenadas) y cerca (<100 píxeles) de otra persona. Ajusté el threshold de 50 a 100 para captar más movimientos en peleas de hockey.\n",
        "- **Métricas**: F1-score para roles, comparando con ground truth. Puedes añadir PCK para poses:\n",
        "  ```python\n",
        "  def pck(pred_keypoints, gt_keypoints, threshold=0.05):\n",
        "      distances = np.sqrt(np.sum((pred_keypoints - gt_keypoints)**2, axis=1))\n",
        "      return np.mean(distances < threshold * 192)\n",
        "  ```\n",
        "- **Optimización**: Redimensiona frames a 640x480 para evitar saturar memoria. Limita frames si es necesario:\n",
        "  ```python\n",
        "  if frame_count > 300: break  # 10 seg a 30fps\n",
        "  ```\n",
        "\n",
        "### Consejos\n",
        "- **Debugging**: Si el video no carga, verifica el path con `!ls fights/`. Si YOLO falla, usa `yolo = YOLO('yolov8s.pt')` (más robusto pero lento).\n",
        "- **Dataset**: Los videos de \"fights\" son ideales para detectar agresor/víctima. Prueba `no_fights/` para verificar falsos positivos.\n",
        "- **Mejoras**:\n",
        "  - Usa optical flow (`cv2.calcOpticalFlowFarneback`) para confirmar movimientos agresivos.\n",
        "  - Fine-tunea MoveNet con RWF-2000 si la heurística es imprecisa.\n",
        "- **Ética**: Los videos de hockey son públicos, pero anonimiza rostros si usas datos propios (con Mediapipe).\n",
        "\n",
        "Si no tienes una cuenta de Kaggle o el dataset falla, prueba un video alternativo como `people-detection.mp4` de Intel (https://github.com/intel-iot-devkit/sample-videos). ¿Quieres ayuda con otro video, métricas específicas o ajustar la heurística? ¡Cuéntame cómo sale!"
      ],
      "metadata": {
        "id": "7cv6xIM-NKDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar dependencias\n",
        "!pip install -q tensorflow tensorflow-hub opencv-python-headless ultralytics sklearn\n",
        "!pip install -q kaggle\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# 2. Configurar Kaggle API\n",
        "print(\"Sube tu kaggle.json (descárgalo desde Kaggle > Account > Create API Token)\")\n",
        "uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 3. Descargar y descomprimir Hockey Fight Videos dataset\n",
        "!kaggle datasets download -d yassershrief/hockey-fight-vidoes\n",
        "!unzip -q hockey-fight-vidoes.zip\n",
        "\n",
        "# 4. Cargar modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')  # Modelo YOLOv8 preentrenado\n",
        "\n",
        "# 5. Preprocesar frame para MoveNet\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# 6. Detectar poses\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [persona, keypoints, (y, x, conf)]\n",
        "    return keypoints\n",
        "\n",
        "# 7. Analizar movimiento para roles (heurística: mano derecha alta y cerca)\n",
        "def analyze_roles(keypoints_list, person_boxes):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        right_wrist = keypoints[10]  # Mano derecha: [y, x, conf]\n",
        "        if right_wrist[2] > 0.3:  # Confianza suficiente\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:  # Evita compararse consigo mismo\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    if abs(wrist_x * 192 - ox) < 100 and wrist_y * 192 < oy:  # Mano alta y cerca\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'víctima'))\n",
        "                        return roles\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]  # Default si no hay detección\n",
        "\n",
        "# 8. Calcular métricas (F1-score para roles)\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if y_true and y_pred and len(y_true) == len(y_pred):\n",
        "        f1 = f1_score(y_true, y_pred, labels=['agresor', 'víctima', 'desconocido'], average='weighted')\n",
        "        return f1\n",
        "    return 0.0\n",
        "\n",
        "# 9. Procesar video\n",
        "def process_video(video_path, output_path='output_hockey.mp4', ground_truth_roles=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: No se pudo abrir el video {video_path}\")\n",
        "        return None\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Reducir resolución para rapidez (opcional)\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        width, height = 640, 480\n",
        "\n",
        "        # Detectar personas con YOLOv8\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if box.cls == 0:  # 0 es 'person' en COCO\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Aplicar MoveNet a cada persona\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))  # Dummy si crop falla\n",
        "\n",
        "        # Analizar roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes)\n",
        "        all_pred_roles.append(roles)\n",
        "\n",
        "        # Dibujar resultados\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            # Etiquetas: rojo para agresor, azul para víctima\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx, ky = int(kp[1] * w + x), int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 5, (255, 255, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0:\n",
        "            print(f\"Procesados {frame_count} frames\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Calcular métricas si hay ground truth\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"Video procesado guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# 10. Seleccionar un video y procesar\n",
        "video_path = 'fights/fi001.mp4'  # Ajusta según el nombre exacto (verifica con !ls fights/)\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo, ajusta si tienes CSV\n",
        "output_path = process_video(video_path, 'output_hockey.mp4', ground_truth_roles)\n",
        "\n",
        "# 11. Descargar resultado\n",
        "if output_path and os.path.exists(output_path):\n",
        "    files.download(output_path)\n",
        "else:\n",
        "    print(\"Error: No se generó el video de salida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "SSdLQSPgNKVP",
        "outputId": "a59ad6c0-0351-4a37-fcc5-0f0db76c0219"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Sube tu kaggle.json (descárgalo desde Kaggle > Account > Create API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a15d24c-7598-417a-9e4b-66fbdcff5a1a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a15d24c-7598-417a-9e4b-66fbdcff5a1a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/yassershrief/hockey-fight-vidoes\n",
            "License(s): unknown\n",
            "Downloading hockey-fight-vidoes.zip to /content\n",
            " 70% 114M/164M [00:00<00:00, 1.18GB/s]\n",
            "100% 164M/164M [00:00<00:00, 739MB/s] \n",
            "Error: No se pudo abrir el video fights/fi001.mp4\n",
            "Error: No se generó el video de salida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 1: Instalar dependencias (con fix para kaggle)\n",
        "!pip install -q tensorflow tensorflow-hub opencv-python-headless ultralytics sklearn\n",
        "!pip install --no-cache-dir -q kaggle  # Fix para metadata error\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Celda 2: Configurar Kaggle API (con renombrado automático)\n",
        "print(\"Sube tu kaggle.json (desde Kaggle > Account > Create API Token)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Renombrar si es necesario (maneja 'kaggle (1).json')\n",
        "json_file = None\n",
        "for filename in uploaded.keys():\n",
        "    if 'kaggle' in filename.lower() and filename.endswith('.json'):\n",
        "        json_file = filename\n",
        "        break\n",
        "\n",
        "if json_file:\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp \"{json_file}\" ~/.kaggle/kaggle.json  # Usa comillas para espacios\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(f\"Archivo configurado: {json_file}\")\n",
        "else:\n",
        "    print(\"Error: No se encontró kaggle.json. Sube el archivo correcto.\")\n",
        "    raise ValueError(\"Sube kaggle.json\")\n",
        "\n",
        "# Celda 3: Descargar y descomprimir dataset\n",
        "!kaggle datasets download -d yassershrief/hockey-fight-vidoes\n",
        "!unzip -q hockey-fight-vidoes.zip -d /content/hockey_dataset/\n",
        "\n",
        "# Listar videos para verificar\n",
        "print(\"Videos en fights/:\")\n",
        "!ls /content/hockey_dataset/fights/ | head -10\n",
        "print(\"\\nVideos en no_fights/:\")\n",
        "!ls /content/hockey_dataset/no_fights/ | head -10\n",
        "\n",
        "# Celda 4: Cargar modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')  # Ligero y rápido\n",
        "\n",
        "# Celda 5: Funciones (preprocesar, detectar, analizar roles)\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]  # [17 keypoints, (y, x, conf)]\n",
        "    return keypoints\n",
        "\n",
        "def analyze_roles(keypoints_list, person_boxes):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        right_wrist = keypoints[10]  # Mano derecha\n",
        "        if right_wrist[2] > 0.3:  # Confianza\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    # Ajustado para hockey: threshold más amplio (100 px) y mano \"alta\" (baja y en coords)\n",
        "                    if abs(wrist_x * 192 - (ox + ow/2)) < 100 and wrist_y * height < oy + oh/2:  # Cerca del centro de la otra persona\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'víctima'))\n",
        "                        return roles\n",
        "    # Default\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]\n",
        "\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if y_true and y_pred and len(y_true) == len(y_pred):\n",
        "        return f1_score(y_true, y_pred, labels=['agresor', 'víctima', 'desconocido'], average='weighted')\n",
        "    return 0.0\n",
        "\n",
        "# Celda 6: Función para procesar video\n",
        "def process_video(video_path, output_path='output_hockey.mp4', ground_truth_roles=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: No se pudo abrir {video_path}\")\n",
        "        return None\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize para eficiencia\n",
        "        frame_resized = cv2.resize(frame, (640, 480))\n",
        "        r_width, r_height = 640, 480\n",
        "\n",
        "        # Detectar personas\n",
        "        results = yolo(frame_resized)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if int(box.cls) == 0:  # Persona\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Poses\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame_resized[y:y+h, x:x+w]\n",
        "            if person_crop.size > 0 and w > 50 and h > 100:  # Evita crops pequeños\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))\n",
        "\n",
        "        # Roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes)\n",
        "        all_pred_roles.append(roles)\n",
        "\n",
        "        # Dibujar\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            # Colores: rojo=agresor, azul=víctima, gris=desconocido\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame_resized, role.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            # Keypoints\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx = int(kp[1] * w + x)\n",
        "                    ky = int(kp[0] * h + y)\n",
        "                    cv2.circle(frame_resized, (kx, ky), 3, (255, 255, 0), -1)\n",
        "\n",
        "        out.write(frame_resized)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:  # Progreso cada seg\n",
        "            print(f\"Procesados {frame_count} frames...\")\n",
        "\n",
        "        # Limita a 300 frames (~10 seg) para pruebas rápidas\n",
        "        if frame_count >= 300:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0] if all_pred_roles else [])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"¡Listo! Video guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Celda 7: Procesar un video de ejemplo\n",
        "# Elige uno de fights/ (ver lista arriba). Ejemplo: fi001.mp4 (común en este dataset)\n",
        "video_path = '/content/hockey_dataset/fights/fi001.mp4'  # Ajusta si el nombre es diferente (ej. 00001.mp4)\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo; ajusta con reales\n",
        "\n",
        "if os.path.exists(video_path):\n",
        "    output_path = process_video(video_path, 'output_hockey.mp4', ground_truth_roles)\n",
        "    files.download(output_path)\n",
        "else:\n",
        "    print(f\"Video no encontrado: {video_path}. Usa !ls para ver nombres exactos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "tTzNb3LhOdp6",
        "outputId": "bf0ed29e-2b3c-49ef-cbf3-2e35631cb42e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Sube tu kaggle.json (desde Kaggle > Account > Create API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f782ae72-a2eb-435a-97c4-bcd77b22cbec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f782ae72-a2eb-435a-97c4-bcd77b22cbec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n",
            "Archivo configurado: kaggle (2).json\n",
            "Dataset URL: https://www.kaggle.com/datasets/yassershrief/hockey-fight-vidoes\n",
            "License(s): unknown\n",
            "hockey-fight-vidoes.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Videos en fights/:\n",
            "ls: cannot access '/content/hockey_dataset/fights/': No such file or directory\n",
            "\n",
            "Videos en no_fights/:\n",
            "ls: cannot access '/content/hockey_dataset/no_fights/': No such file or directory\n",
            "Video no encontrado: /content/hockey_dataset/fights/fi001.mp4. Usa !ls para ver nombres exactos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 1: Instalar dependencias\n",
        "!pip install -q tensorflow tensorflow-hub opencv-python-headless ultralytics scikit-learn\n",
        "!pip install --no-cache-dir -q kaggle  # Evita error de metadata\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Celda 2: Configurar Kaggle API\n",
        "print(\"Sube tu kaggle.json (desde Kaggle > Account > Create API Token)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "json_file = None\n",
        "for filename in uploaded.keys():\n",
        "    if 'kaggle' in filename.lower() and filename.endswith('.json'):\n",
        "        json_file = filename\n",
        "        break\n",
        "\n",
        "if json_file:\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp \"{json_file}\" ~/.kaggle/kaggle.json\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(f\"Archivo configurado: {json_file}\")\n",
        "else:\n",
        "    print(\"Error: No se encontró kaggle.json\")\n",
        "    raise ValueError(\"Sube kaggle.json\")\n",
        "\n",
        "# Celda 3: Descargar y descomprimir dataset\n",
        "# Borrar cualquier zip previo para evitar conflictos\n",
        "!rm -f hockey-fight-vidoes.zip\n",
        "# Forzar descarga\n",
        "!kaggle datasets download -d yassershrief/hockey-fight-vidoes --force\n",
        "# Crear carpeta y descomprimir\n",
        "!mkdir -p /content/hockey_dataset\n",
        "!unzip -o hockey-fight-vidoes.zip -d /content/hockey_dataset/\n",
        "\n",
        "# Verificar archivos\n",
        "print(\"Contenido de /content/hockey_dataset/:\")\n",
        "!ls -R /content/hockey_dataset/\n",
        "\n",
        "# Celda 4: Cargar modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')\n",
        "\n",
        "# Celda 5: Funciones\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]\n",
        "    return keypoints\n",
        "\n",
        "def analyze_roles(keypoints_list, person_boxes, height):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        right_wrist = keypoints[10]  # Mano derecha\n",
        "        if right_wrist[2] > 0.3:\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    if abs(wrist_x * 192 - (ox + ow/2)) < 100 and wrist_y * height < oy + oh/2:\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'víctima'))\n",
        "                        return roles\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]\n",
        "\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if y_true and y_pred and len(y_true) == len(y_pred):\n",
        "        return f1_score(y_true, y_pred, labels=['agresor', 'víctima', 'desconocido'], average='weighted')\n",
        "    return 0.0\n",
        "\n",
        "def process_video(video_path, output_path='output_hockey.mp4', ground_truth_roles=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: No se pudo abrir {video_path}\")\n",
        "        return None\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        r_width, r_height = 640, 480\n",
        "\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if int(box.cls) == 0:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0 and w > 50 and h > 100:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))\n",
        "\n",
        "        roles = analyze_roles(keypoints_list, person_boxes, r_height)\n",
        "        all_pred_roles.append(roles)\n",
        "\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx = int(kp[1] * w + x)\n",
        "                    ky = int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 3, (255, 255, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Procesados {frame_count} frames...\")\n",
        "        if frame_count >= 300:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0] if all_pred_roles else [])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"¡Listo! Video guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Celda 6: Procesar video\n",
        "# Ajusta el nombre según la salida de !ls\n",
        "video_path = '/content/hockey_dataset/fights/fi001.mp4'  # Verifica con !ls\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo\n",
        "\n",
        "if os.path.exists(video_path):\n",
        "    output_path = process_video(video_path, 'output_hockey.mp4', ground_truth_roles)\n",
        "    if output_path:\n",
        "        files.download(output_path)\n",
        "else:\n",
        "    print(f\"Video no encontrado: {video_path}\")\n",
        "    print(\"Verifica nombres con:\")\n",
        "    !ls /content/hockey_dataset/fights/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3n_s2e4lPA69",
        "outputId": "6a81d813-0739-430e-901d-af1e24d580c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube tu kaggle.json (desde Kaggle > Account > Create API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dcb4fd80-6574-4ef8-8327-b069f91eb17b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dcb4fd80-6574-4ef8-8327-b069f91eb17b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (3).json\n",
            "Archivo configurado: kaggle (3).json\n",
            "Dataset URL: https://www.kaggle.com/datasets/yassershrief/hockey-fight-vidoes\n",
            "License(s): unknown\n",
            "Downloading hockey-fight-vidoes.zip to /content\n",
            " 81% 133M/164M [00:00<00:00, 1.38GB/s]\n",
            "100% 164M/164M [00:00<00:00, 1.09GB/s]\n",
            "Archive:  hockey-fight-vidoes.zip\n",
            "  inflating: /content/hockey_dataset/data/fi100_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi101_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi102_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi103_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi104_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi105_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi106_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi107_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi108_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi109_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi10_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi110_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi111_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi112_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi113_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi114_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi115_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi116_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi117_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi118_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi119_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi11_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi120_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi121_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi122_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi123_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi124_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi125_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi126_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi127_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi128_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi129_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi12_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi130_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi131_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi132_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi133_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi134_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi135_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi136_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi137_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi138_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi139_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi13_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi140_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi141_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi142_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi143_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi144_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi145_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi146_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi147_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi148_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi149_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi14_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi150_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi151_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi152_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi153_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi154_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi155_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi156_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi157_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi158_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi159_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi15_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi160_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi161_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi162_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi163_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi164_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi165_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi166_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi167_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi168_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi169_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi16_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi170_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi171_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi172_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi173_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi174_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi175_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi176_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi177_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi178_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi179_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi17_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi180_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi181_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi182_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi183_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi184_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi185_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi186_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi187_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi188_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi189_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi18_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi190_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi191_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi192_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi193_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi194_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi195_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi196_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi197_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi198_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi199_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi19_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi1_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi200_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi201_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi202_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi203_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi204_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi205_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi206_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi207_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi208_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi209_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi20_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi210_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi211_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi212_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi213_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi214_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi215_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi216_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi217_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi218_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi219_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi21_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi220_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi221_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi222_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi223_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi224_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi225_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi226_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi227_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi228_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi229_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi22_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi230_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi231_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi232_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi233_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi234_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi235_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi236_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi237_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi238_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi239_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi23_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi240_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi241_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi242_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi243_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi244_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi245_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi246_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi247_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi248_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi249_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi24_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi250_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi251_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi252_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi253_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi254_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi255_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi256_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi257_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi258_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi259_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi25_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi260_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi261_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi262_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi263_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi264_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi265_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi266_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi267_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi268_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi269_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi26_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi270_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi271_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi272_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi273_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi274_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi275_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi276_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi277_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi278_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi279_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi27_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi280_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi281_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi282_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi283_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi284_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi285_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi286_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi287_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi288_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi289_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi28_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi290_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi291_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi292_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi293_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi294_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi295_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi296_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi297_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi298_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi299_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi29_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi2_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi300_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi301_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi302_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi303_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi304_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi305_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi306_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi307_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi308_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi309_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi30_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi310_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi311_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi312_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi313_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi314_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi315_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi316_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi317_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi318_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi319_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi31_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi320_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi321_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi322_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi323_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi324_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi325_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi326_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi327_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi328_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi329_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi32_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi330_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi331_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi332_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi333_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi334_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi335_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi336_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi337_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi338_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi339_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi33_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi340_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi341_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi342_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi343_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi344_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi345_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi346_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi347_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi348_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi349_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi34_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi350_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi351_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi352_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi353_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi354_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi355_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi356_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi357_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi358_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi359_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi35_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi360_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi361_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi362_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi363_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi364_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi365_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi366_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi367_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi368_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi369_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi36_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi370_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi371_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi372_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi373_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi374_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi375_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi376_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi377_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi378_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi379_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi37_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi380_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi381_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi382_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi383_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi384_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi385_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi386_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi387_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi388_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi389_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi38_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi390_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi391_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi392_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi393_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi394_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi395_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi396_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi397_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi398_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi399_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi39_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi3_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi400_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi401_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi402_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi403_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi404_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi405_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi406_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi407_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi408_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi409_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi40_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi410_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi411_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi412_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi413_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi414_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi415_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi416_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi417_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi418_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi419_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi41_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi420_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi421_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi422_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi423_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi424_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi425_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi426_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi427_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi428_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi429_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi42_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi430_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi431_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi432_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi433_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi434_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi435_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi436_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi437_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi438_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi439_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi43_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi440_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi441_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi442_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi443_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi444_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi445_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi446_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi447_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi448_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi449_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi44_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi450_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi451_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi452_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi453_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi454_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi455_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi456_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi457_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi458_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi459_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi45_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi460_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi461_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi462_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi463_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi464_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi465_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi466_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi467_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi468_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi469_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi46_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi470_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi471_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi472_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi473_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi474_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi475_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi476_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi477_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi478_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi479_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi47_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi480_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi481_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi482_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi483_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi484_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi485_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi486_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi487_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi488_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi489_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi48_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi490_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi491_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi492_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi493_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi494_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi495_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi496_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi497_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi498_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi499_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi49_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi4_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi500_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi50_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi51_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi52_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi53_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi54_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi55_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi56_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi57_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi58_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi59_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi5_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi60_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi61_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi62_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi63_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi64_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi65_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi66_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi67_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi68_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi69_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi6_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi70_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi71_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi72_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi73_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi74_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi75_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi76_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi77_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi78_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi79_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi7_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi80_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi81_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi82_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi83_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi84_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi85_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi86_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi87_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi88_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi89_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi8_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi90_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi91_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi92_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi93_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi94_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi95_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi96_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi97_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi98_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi99_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/fi9_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no100_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no101_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no102_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no103_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no104_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no105_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no106_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no107_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no108_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no109_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no10_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no110_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no111_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no112_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no113_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no114_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no115_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no116_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no117_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no118_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no119_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no11_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no120_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no121_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no122_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no123_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no124_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no125_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no126_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no127_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no128_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no129_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no12_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no130_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no131_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no132_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no133_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no134_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no135_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no136_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no137_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no138_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no139_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no13_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no140_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no141_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no142__xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no143_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no144_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no145_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no146_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no147_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no148_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no149_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no14_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no150_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no151_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no152_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no153_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no154_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no155_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no156_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no157_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no158_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no159_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no15_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no160_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no161_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no162_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no163_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no164_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no165_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no166_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no167_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no168_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no169_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no16_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no170_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no171_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no172_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no173_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no174_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no175_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no176_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no177_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no178_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no179_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no17_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no180_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no181_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no182_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no183_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no184_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no185_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no186_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no187_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no188_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no189_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no18_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no190_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no191_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no192_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no193_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no194_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no195_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no196_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no197_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no198_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no199_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no19_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no1_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no200_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no201_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no202_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no203_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no204_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no205_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no206_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no207_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no208_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no209_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no20_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no210_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no211_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no212_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no213_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no214_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no215_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no216_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no217_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no218_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no219_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no21_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no220_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no221_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no222_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no223_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no224_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no225_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no226_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no227_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no228_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no229_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no22_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no230_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no231_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no232_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no233_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no234_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no235_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no236_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no237_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no238mpg_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no239_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no23_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no240_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no241_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no242_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no243_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no244_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no245_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no246_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no247_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no248_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no249_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no24_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no250_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no251_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no252_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no253_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no254_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no255_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no256_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no257_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no258_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no259_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no25_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no260_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no261_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no262_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no263_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no264_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no265_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no266_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no267_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no268_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no269_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no26_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no270_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no271_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no272_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no273_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no274_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no275_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no276_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no277_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no278_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no279_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no27_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no280_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no281_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no282_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no283_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no284_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no285_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no286_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no287_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no288_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no289_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no28_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no290_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no291_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no292_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no293_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no294_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no295_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no296_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no297_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no298_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no299_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no29_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no2_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no300_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no301_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no302_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no303_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no304_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no305_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no306_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no307_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no308_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no309_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no30_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no310_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no311_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no312_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no313_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no314_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no315_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no316_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no317_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no318_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no319_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no31_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no320_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no321_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no322_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no323_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no324_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no325_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no326_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no327_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no328_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no329_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no32_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no330_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no331_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no332_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no333_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no334_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no335_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no336_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no337_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no338_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no339_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no33_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no340_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no341_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no342_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no343_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no344_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no345_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no346_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no347_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no348_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no349_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no34_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no350_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no351_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no352_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no353_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no354_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no355_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no356_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no357_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no358_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no359_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no35_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no360_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no361_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no362_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no363_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no364_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no365_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no366_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no367_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no368_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no369_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no36_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no370_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no371_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no372_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no373_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no374_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no375_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no376_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no377_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no378_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no379_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no37_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no380_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no381_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no382_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no383_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no384_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no385_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no386_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no387_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no388_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no389_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no38_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no390_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no391_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no392_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no393_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no394_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no395_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no396_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no397_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no398_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no399_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no39_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no3_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no400_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no401_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no402_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no403_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no404_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no405_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no406_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no407_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no408_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no409_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no40_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no410_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no411_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no412_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no413_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no414_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no415_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no416_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no417_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no418_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no419_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no41_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no420_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no421_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no422_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no423_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no424_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no425_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no426_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no427_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no428_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no429_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no42_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no430_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no431_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no432_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no433_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no434_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no435_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no436_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no437_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no438_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no439_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no43_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no440_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no441_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no442_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no443_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no444_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no445_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no446_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no447_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no448_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no449_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no44_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no450_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no451_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no452_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no453_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no454_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no455_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no456_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no457_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no458_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no459_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no45_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no460_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no461_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no462_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no463_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no464_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no465_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no466_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no467_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no468_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no469_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no46_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no470_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no471_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no472_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no473_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no474_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no475_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no476_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no477_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no478_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no479_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no47_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no480_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no481_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no482_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no483_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no484_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no485_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no486_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no487_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no488_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no489_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no48_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no490_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no491_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no492_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no493_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no494_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no495_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no496_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no497_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no498_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no499_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no49_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no4_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no500_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no50_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no51_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no52_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no53_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no54_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no55_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no56_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no57_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no58_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no59_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no5_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no60_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no61_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no62_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no63_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no64_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no65___xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no66_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no67_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no68_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no69_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no6_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no70_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no71_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no72_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no73_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no74_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no75_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no76_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no77_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no78_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no79_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no7_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no80_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no81_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no82_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no83_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no84_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no85_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no86_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no87_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no88_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no89_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no8_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no90_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no91_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no92_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no93_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no94_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no95_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no96_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no97_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no98_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no99_xvid.avi  \n",
            "  inflating: /content/hockey_dataset/data/no9_xvid.avi  \n",
            "Contenido de /content/hockey_dataset/:\n",
            "/content/hockey_dataset/:\n",
            "data\n",
            "\n",
            "/content/hockey_dataset/data:\n",
            "fi100_xvid.avi\tfi326_xvid.avi\tno100_xvid.avi\t   no326_xvid.avi\n",
            "fi101_xvid.avi\tfi327_xvid.avi\tno101_xvid.avi\t   no327_xvid.avi\n",
            "fi102_xvid.avi\tfi328_xvid.avi\tno102_xvid.avi\t   no328_xvid.avi\n",
            "fi103_xvid.avi\tfi329_xvid.avi\tno103_xvid.avi\t   no329_xvid.avi\n",
            "fi104_xvid.avi\tfi32_xvid.avi\tno104_xvid.avi\t   no32_xvid.avi\n",
            "fi105_xvid.avi\tfi330_xvid.avi\tno105_xvid.avi\t   no330_xvid.avi\n",
            "fi106_xvid.avi\tfi331_xvid.avi\tno106_xvid.avi\t   no331_xvid.avi\n",
            "fi107_xvid.avi\tfi332_xvid.avi\tno107_xvid.avi\t   no332_xvid.avi\n",
            "fi108_xvid.avi\tfi333_xvid.avi\tno108_xvid.avi\t   no333_xvid.avi\n",
            "fi109_xvid.avi\tfi334_xvid.avi\tno109_xvid.avi\t   no334_xvid.avi\n",
            "fi10_xvid.avi\tfi335_xvid.avi\tno10_xvid.avi\t   no335_xvid.avi\n",
            "fi110_xvid.avi\tfi336_xvid.avi\tno110_xvid.avi\t   no336_xvid.avi\n",
            "fi111_xvid.avi\tfi337_xvid.avi\tno111_xvid.avi\t   no337_xvid.avi\n",
            "fi112_xvid.avi\tfi338_xvid.avi\tno112_xvid.avi\t   no338_xvid.avi\n",
            "fi113_xvid.avi\tfi339_xvid.avi\tno113_xvid.avi\t   no339_xvid.avi\n",
            "fi114_xvid.avi\tfi33_xvid.avi\tno114_xvid.avi\t   no33_xvid.avi\n",
            "fi115_xvid.avi\tfi340_xvid.avi\tno115_xvid.avi\t   no340_xvid.avi\n",
            "fi116_xvid.avi\tfi341_xvid.avi\tno116_xvid.avi\t   no341_xvid.avi\n",
            "fi117_xvid.avi\tfi342_xvid.avi\tno117_xvid.avi\t   no342_xvid.avi\n",
            "fi118_xvid.avi\tfi343_xvid.avi\tno118_xvid.avi\t   no343_xvid.avi\n",
            "fi119_xvid.avi\tfi344_xvid.avi\tno119_xvid.avi\t   no344_xvid.avi\n",
            "fi11_xvid.avi\tfi345_xvid.avi\tno11_xvid.avi\t   no345_xvid.avi\n",
            "fi120_xvid.avi\tfi346_xvid.avi\tno120_xvid.avi\t   no346_xvid.avi\n",
            "fi121_xvid.avi\tfi347_xvid.avi\tno121_xvid.avi\t   no347_xvid.avi\n",
            "fi122_xvid.avi\tfi348_xvid.avi\tno122_xvid.avi\t   no348_xvid.avi\n",
            "fi123_xvid.avi\tfi349_xvid.avi\tno123_xvid.avi\t   no349_xvid.avi\n",
            "fi124_xvid.avi\tfi34_xvid.avi\tno124_xvid.avi\t   no34_xvid.avi\n",
            "fi125_xvid.avi\tfi350_xvid.avi\tno125_xvid.avi\t   no350_xvid.avi\n",
            "fi126_xvid.avi\tfi351_xvid.avi\tno126_xvid.avi\t   no351_xvid.avi\n",
            "fi127_xvid.avi\tfi352_xvid.avi\tno127_xvid.avi\t   no352_xvid.avi\n",
            "fi128_xvid.avi\tfi353_xvid.avi\tno128_xvid.avi\t   no353_xvid.avi\n",
            "fi129_xvid.avi\tfi354_xvid.avi\tno129_xvid.avi\t   no354_xvid.avi\n",
            "fi12_xvid.avi\tfi355_xvid.avi\tno12_xvid.avi\t   no355_xvid.avi\n",
            "fi130_xvid.avi\tfi356_xvid.avi\tno130_xvid.avi\t   no356_xvid.avi\n",
            "fi131_xvid.avi\tfi357_xvid.avi\tno131_xvid.avi\t   no357_xvid.avi\n",
            "fi132_xvid.avi\tfi358_xvid.avi\tno132_xvid.avi\t   no358_xvid.avi\n",
            "fi133_xvid.avi\tfi359_xvid.avi\tno133_xvid.avi\t   no359_xvid.avi\n",
            "fi134_xvid.avi\tfi35_xvid.avi\tno134_xvid.avi\t   no35_xvid.avi\n",
            "fi135_xvid.avi\tfi360_xvid.avi\tno135_xvid.avi\t   no360_xvid.avi\n",
            "fi136_xvid.avi\tfi361_xvid.avi\tno136_xvid.avi\t   no361_xvid.avi\n",
            "fi137_xvid.avi\tfi362_xvid.avi\tno137_xvid.avi\t   no362_xvid.avi\n",
            "fi138_xvid.avi\tfi363_xvid.avi\tno138_xvid.avi\t   no363_xvid.avi\n",
            "fi139_xvid.avi\tfi364_xvid.avi\tno139_xvid.avi\t   no364_xvid.avi\n",
            "fi13_xvid.avi\tfi365_xvid.avi\tno13_xvid.avi\t   no365_xvid.avi\n",
            "fi140_xvid.avi\tfi366_xvid.avi\tno140_xvid.avi\t   no366_xvid.avi\n",
            "fi141_xvid.avi\tfi367_xvid.avi\tno141_xvid.avi\t   no367_xvid.avi\n",
            "fi142_xvid.avi\tfi368_xvid.avi\tno142__xvid.avi    no368_xvid.avi\n",
            "fi143_xvid.avi\tfi369_xvid.avi\tno143_xvid.avi\t   no369_xvid.avi\n",
            "fi144_xvid.avi\tfi36_xvid.avi\tno144_xvid.avi\t   no36_xvid.avi\n",
            "fi145_xvid.avi\tfi370_xvid.avi\tno145_xvid.avi\t   no370_xvid.avi\n",
            "fi146_xvid.avi\tfi371_xvid.avi\tno146_xvid.avi\t   no371_xvid.avi\n",
            "fi147_xvid.avi\tfi372_xvid.avi\tno147_xvid.avi\t   no372_xvid.avi\n",
            "fi148_xvid.avi\tfi373_xvid.avi\tno148_xvid.avi\t   no373_xvid.avi\n",
            "fi149_xvid.avi\tfi374_xvid.avi\tno149_xvid.avi\t   no374_xvid.avi\n",
            "fi14_xvid.avi\tfi375_xvid.avi\tno14_xvid.avi\t   no375_xvid.avi\n",
            "fi150_xvid.avi\tfi376_xvid.avi\tno150_xvid.avi\t   no376_xvid.avi\n",
            "fi151_xvid.avi\tfi377_xvid.avi\tno151_xvid.avi\t   no377_xvid.avi\n",
            "fi152_xvid.avi\tfi378_xvid.avi\tno152_xvid.avi\t   no378_xvid.avi\n",
            "fi153_xvid.avi\tfi379_xvid.avi\tno153_xvid.avi\t   no379_xvid.avi\n",
            "fi154_xvid.avi\tfi37_xvid.avi\tno154_xvid.avi\t   no37_xvid.avi\n",
            "fi155_xvid.avi\tfi380_xvid.avi\tno155_xvid.avi\t   no380_xvid.avi\n",
            "fi156_xvid.avi\tfi381_xvid.avi\tno156_xvid.avi\t   no381_xvid.avi\n",
            "fi157_xvid.avi\tfi382_xvid.avi\tno157_xvid.avi\t   no382_xvid.avi\n",
            "fi158_xvid.avi\tfi383_xvid.avi\tno158_xvid.avi\t   no383_xvid.avi\n",
            "fi159_xvid.avi\tfi384_xvid.avi\tno159_xvid.avi\t   no384_xvid.avi\n",
            "fi15_xvid.avi\tfi385_xvid.avi\tno15_xvid.avi\t   no385_xvid.avi\n",
            "fi160_xvid.avi\tfi386_xvid.avi\tno160_xvid.avi\t   no386_xvid.avi\n",
            "fi161_xvid.avi\tfi387_xvid.avi\tno161_xvid.avi\t   no387_xvid.avi\n",
            "fi162_xvid.avi\tfi388_xvid.avi\tno162_xvid.avi\t   no388_xvid.avi\n",
            "fi163_xvid.avi\tfi389_xvid.avi\tno163_xvid.avi\t   no389_xvid.avi\n",
            "fi164_xvid.avi\tfi38_xvid.avi\tno164_xvid.avi\t   no38_xvid.avi\n",
            "fi165_xvid.avi\tfi390_xvid.avi\tno165_xvid.avi\t   no390_xvid.avi\n",
            "fi166_xvid.avi\tfi391_xvid.avi\tno166_xvid.avi\t   no391_xvid.avi\n",
            "fi167_xvid.avi\tfi392_xvid.avi\tno167_xvid.avi\t   no392_xvid.avi\n",
            "fi168_xvid.avi\tfi393_xvid.avi\tno168_xvid.avi\t   no393_xvid.avi\n",
            "fi169_xvid.avi\tfi394_xvid.avi\tno169_xvid.avi\t   no394_xvid.avi\n",
            "fi16_xvid.avi\tfi395_xvid.avi\tno16_xvid.avi\t   no395_xvid.avi\n",
            "fi170_xvid.avi\tfi396_xvid.avi\tno170_xvid.avi\t   no396_xvid.avi\n",
            "fi171_xvid.avi\tfi397_xvid.avi\tno171_xvid.avi\t   no397_xvid.avi\n",
            "fi172_xvid.avi\tfi398_xvid.avi\tno172_xvid.avi\t   no398_xvid.avi\n",
            "fi173_xvid.avi\tfi399_xvid.avi\tno173_xvid.avi\t   no399_xvid.avi\n",
            "fi174_xvid.avi\tfi39_xvid.avi\tno174_xvid.avi\t   no39_xvid.avi\n",
            "fi175_xvid.avi\tfi3_xvid.avi\tno175_xvid.avi\t   no3_xvid.avi\n",
            "fi176_xvid.avi\tfi400_xvid.avi\tno176_xvid.avi\t   no400_xvid.avi\n",
            "fi177_xvid.avi\tfi401_xvid.avi\tno177_xvid.avi\t   no401_xvid.avi\n",
            "fi178_xvid.avi\tfi402_xvid.avi\tno178_xvid.avi\t   no402_xvid.avi\n",
            "fi179_xvid.avi\tfi403_xvid.avi\tno179_xvid.avi\t   no403_xvid.avi\n",
            "fi17_xvid.avi\tfi404_xvid.avi\tno17_xvid.avi\t   no404_xvid.avi\n",
            "fi180_xvid.avi\tfi405_xvid.avi\tno180_xvid.avi\t   no405_xvid.avi\n",
            "fi181_xvid.avi\tfi406_xvid.avi\tno181_xvid.avi\t   no406_xvid.avi\n",
            "fi182_xvid.avi\tfi407_xvid.avi\tno182_xvid.avi\t   no407_xvid.avi\n",
            "fi183_xvid.avi\tfi408_xvid.avi\tno183_xvid.avi\t   no408_xvid.avi\n",
            "fi184_xvid.avi\tfi409_xvid.avi\tno184_xvid.avi\t   no409_xvid.avi\n",
            "fi185_xvid.avi\tfi40_xvid.avi\tno185_xvid.avi\t   no40_xvid.avi\n",
            "fi186_xvid.avi\tfi410_xvid.avi\tno186_xvid.avi\t   no410_xvid.avi\n",
            "fi187_xvid.avi\tfi411_xvid.avi\tno187_xvid.avi\t   no411_xvid.avi\n",
            "fi188_xvid.avi\tfi412_xvid.avi\tno188_xvid.avi\t   no412_xvid.avi\n",
            "fi189_xvid.avi\tfi413_xvid.avi\tno189_xvid.avi\t   no413_xvid.avi\n",
            "fi18_xvid.avi\tfi414_xvid.avi\tno18_xvid.avi\t   no414_xvid.avi\n",
            "fi190_xvid.avi\tfi415_xvid.avi\tno190_xvid.avi\t   no415_xvid.avi\n",
            "fi191_xvid.avi\tfi416_xvid.avi\tno191_xvid.avi\t   no416_xvid.avi\n",
            "fi192_xvid.avi\tfi417_xvid.avi\tno192_xvid.avi\t   no417_xvid.avi\n",
            "fi193_xvid.avi\tfi418_xvid.avi\tno193_xvid.avi\t   no418_xvid.avi\n",
            "fi194_xvid.avi\tfi419_xvid.avi\tno194_xvid.avi\t   no419_xvid.avi\n",
            "fi195_xvid.avi\tfi41_xvid.avi\tno195_xvid.avi\t   no41_xvid.avi\n",
            "fi196_xvid.avi\tfi420_xvid.avi\tno196_xvid.avi\t   no420_xvid.avi\n",
            "fi197_xvid.avi\tfi421_xvid.avi\tno197_xvid.avi\t   no421_xvid.avi\n",
            "fi198_xvid.avi\tfi422_xvid.avi\tno198_xvid.avi\t   no422_xvid.avi\n",
            "fi199_xvid.avi\tfi423_xvid.avi\tno199_xvid.avi\t   no423_xvid.avi\n",
            "fi19_xvid.avi\tfi424_xvid.avi\tno19_xvid.avi\t   no424_xvid.avi\n",
            "fi1_xvid.avi\tfi425_xvid.avi\tno1_xvid.avi\t   no425_xvid.avi\n",
            "fi200_xvid.avi\tfi426_xvid.avi\tno200_xvid.avi\t   no426_xvid.avi\n",
            "fi201_xvid.avi\tfi427_xvid.avi\tno201_xvid.avi\t   no427_xvid.avi\n",
            "fi202_xvid.avi\tfi428_xvid.avi\tno202_xvid.avi\t   no428_xvid.avi\n",
            "fi203_xvid.avi\tfi429_xvid.avi\tno203_xvid.avi\t   no429_xvid.avi\n",
            "fi204_xvid.avi\tfi42_xvid.avi\tno204_xvid.avi\t   no42_xvid.avi\n",
            "fi205_xvid.avi\tfi430_xvid.avi\tno205_xvid.avi\t   no430_xvid.avi\n",
            "fi206_xvid.avi\tfi431_xvid.avi\tno206_xvid.avi\t   no431_xvid.avi\n",
            "fi207_xvid.avi\tfi432_xvid.avi\tno207_xvid.avi\t   no432_xvid.avi\n",
            "fi208_xvid.avi\tfi433_xvid.avi\tno208_xvid.avi\t   no433_xvid.avi\n",
            "fi209_xvid.avi\tfi434_xvid.avi\tno209_xvid.avi\t   no434_xvid.avi\n",
            "fi20_xvid.avi\tfi435_xvid.avi\tno20_xvid.avi\t   no435_xvid.avi\n",
            "fi210_xvid.avi\tfi436_xvid.avi\tno210_xvid.avi\t   no436_xvid.avi\n",
            "fi211_xvid.avi\tfi437_xvid.avi\tno211_xvid.avi\t   no437_xvid.avi\n",
            "fi212_xvid.avi\tfi438_xvid.avi\tno212_xvid.avi\t   no438_xvid.avi\n",
            "fi213_xvid.avi\tfi439_xvid.avi\tno213_xvid.avi\t   no439_xvid.avi\n",
            "fi214_xvid.avi\tfi43_xvid.avi\tno214_xvid.avi\t   no43_xvid.avi\n",
            "fi215_xvid.avi\tfi440_xvid.avi\tno215_xvid.avi\t   no440_xvid.avi\n",
            "fi216_xvid.avi\tfi441_xvid.avi\tno216_xvid.avi\t   no441_xvid.avi\n",
            "fi217_xvid.avi\tfi442_xvid.avi\tno217_xvid.avi\t   no442_xvid.avi\n",
            "fi218_xvid.avi\tfi443_xvid.avi\tno218_xvid.avi\t   no443_xvid.avi\n",
            "fi219_xvid.avi\tfi444_xvid.avi\tno219_xvid.avi\t   no444_xvid.avi\n",
            "fi21_xvid.avi\tfi445_xvid.avi\tno21_xvid.avi\t   no445_xvid.avi\n",
            "fi220_xvid.avi\tfi446_xvid.avi\tno220_xvid.avi\t   no446_xvid.avi\n",
            "fi221_xvid.avi\tfi447_xvid.avi\tno221_xvid.avi\t   no447_xvid.avi\n",
            "fi222_xvid.avi\tfi448_xvid.avi\tno222_xvid.avi\t   no448_xvid.avi\n",
            "fi223_xvid.avi\tfi449_xvid.avi\tno223_xvid.avi\t   no449_xvid.avi\n",
            "fi224_xvid.avi\tfi44_xvid.avi\tno224_xvid.avi\t   no44_xvid.avi\n",
            "fi225_xvid.avi\tfi450_xvid.avi\tno225_xvid.avi\t   no450_xvid.avi\n",
            "fi226_xvid.avi\tfi451_xvid.avi\tno226_xvid.avi\t   no451_xvid.avi\n",
            "fi227_xvid.avi\tfi452_xvid.avi\tno227_xvid.avi\t   no452_xvid.avi\n",
            "fi228_xvid.avi\tfi453_xvid.avi\tno228_xvid.avi\t   no453_xvid.avi\n",
            "fi229_xvid.avi\tfi454_xvid.avi\tno229_xvid.avi\t   no454_xvid.avi\n",
            "fi22_xvid.avi\tfi455_xvid.avi\tno22_xvid.avi\t   no455_xvid.avi\n",
            "fi230_xvid.avi\tfi456_xvid.avi\tno230_xvid.avi\t   no456_xvid.avi\n",
            "fi231_xvid.avi\tfi457_xvid.avi\tno231_xvid.avi\t   no457_xvid.avi\n",
            "fi232_xvid.avi\tfi458_xvid.avi\tno232_xvid.avi\t   no458_xvid.avi\n",
            "fi233_xvid.avi\tfi459_xvid.avi\tno233_xvid.avi\t   no459_xvid.avi\n",
            "fi234_xvid.avi\tfi45_xvid.avi\tno234_xvid.avi\t   no45_xvid.avi\n",
            "fi235_xvid.avi\tfi460_xvid.avi\tno235_xvid.avi\t   no460_xvid.avi\n",
            "fi236_xvid.avi\tfi461_xvid.avi\tno236_xvid.avi\t   no461_xvid.avi\n",
            "fi237_xvid.avi\tfi462_xvid.avi\tno237_xvid.avi\t   no462_xvid.avi\n",
            "fi238_xvid.avi\tfi463_xvid.avi\tno238mpg_xvid.avi  no463_xvid.avi\n",
            "fi239_xvid.avi\tfi464_xvid.avi\tno239_xvid.avi\t   no464_xvid.avi\n",
            "fi23_xvid.avi\tfi465_xvid.avi\tno23_xvid.avi\t   no465_xvid.avi\n",
            "fi240_xvid.avi\tfi466_xvid.avi\tno240_xvid.avi\t   no466_xvid.avi\n",
            "fi241_xvid.avi\tfi467_xvid.avi\tno241_xvid.avi\t   no467_xvid.avi\n",
            "fi242_xvid.avi\tfi468_xvid.avi\tno242_xvid.avi\t   no468_xvid.avi\n",
            "fi243_xvid.avi\tfi469_xvid.avi\tno243_xvid.avi\t   no469_xvid.avi\n",
            "fi244_xvid.avi\tfi46_xvid.avi\tno244_xvid.avi\t   no46_xvid.avi\n",
            "fi245_xvid.avi\tfi470_xvid.avi\tno245_xvid.avi\t   no470_xvid.avi\n",
            "fi246_xvid.avi\tfi471_xvid.avi\tno246_xvid.avi\t   no471_xvid.avi\n",
            "fi247_xvid.avi\tfi472_xvid.avi\tno247_xvid.avi\t   no472_xvid.avi\n",
            "fi248_xvid.avi\tfi473_xvid.avi\tno248_xvid.avi\t   no473_xvid.avi\n",
            "fi249_xvid.avi\tfi474_xvid.avi\tno249_xvid.avi\t   no474_xvid.avi\n",
            "fi24_xvid.avi\tfi475_xvid.avi\tno24_xvid.avi\t   no475_xvid.avi\n",
            "fi250_xvid.avi\tfi476_xvid.avi\tno250_xvid.avi\t   no476_xvid.avi\n",
            "fi251_xvid.avi\tfi477_xvid.avi\tno251_xvid.avi\t   no477_xvid.avi\n",
            "fi252_xvid.avi\tfi478_xvid.avi\tno252_xvid.avi\t   no478_xvid.avi\n",
            "fi253_xvid.avi\tfi479_xvid.avi\tno253_xvid.avi\t   no479_xvid.avi\n",
            "fi254_xvid.avi\tfi47_xvid.avi\tno254_xvid.avi\t   no47_xvid.avi\n",
            "fi255_xvid.avi\tfi480_xvid.avi\tno255_xvid.avi\t   no480_xvid.avi\n",
            "fi256_xvid.avi\tfi481_xvid.avi\tno256_xvid.avi\t   no481_xvid.avi\n",
            "fi257_xvid.avi\tfi482_xvid.avi\tno257_xvid.avi\t   no482_xvid.avi\n",
            "fi258_xvid.avi\tfi483_xvid.avi\tno258_xvid.avi\t   no483_xvid.avi\n",
            "fi259_xvid.avi\tfi484_xvid.avi\tno259_xvid.avi\t   no484_xvid.avi\n",
            "fi25_xvid.avi\tfi485_xvid.avi\tno25_xvid.avi\t   no485_xvid.avi\n",
            "fi260_xvid.avi\tfi486_xvid.avi\tno260_xvid.avi\t   no486_xvid.avi\n",
            "fi261_xvid.avi\tfi487_xvid.avi\tno261_xvid.avi\t   no487_xvid.avi\n",
            "fi262_xvid.avi\tfi488_xvid.avi\tno262_xvid.avi\t   no488_xvid.avi\n",
            "fi263_xvid.avi\tfi489_xvid.avi\tno263_xvid.avi\t   no489_xvid.avi\n",
            "fi264_xvid.avi\tfi48_xvid.avi\tno264_xvid.avi\t   no48_xvid.avi\n",
            "fi265_xvid.avi\tfi490_xvid.avi\tno265_xvid.avi\t   no490_xvid.avi\n",
            "fi266_xvid.avi\tfi491_xvid.avi\tno266_xvid.avi\t   no491_xvid.avi\n",
            "fi267_xvid.avi\tfi492_xvid.avi\tno267_xvid.avi\t   no492_xvid.avi\n",
            "fi268_xvid.avi\tfi493_xvid.avi\tno268_xvid.avi\t   no493_xvid.avi\n",
            "fi269_xvid.avi\tfi494_xvid.avi\tno269_xvid.avi\t   no494_xvid.avi\n",
            "fi26_xvid.avi\tfi495_xvid.avi\tno26_xvid.avi\t   no495_xvid.avi\n",
            "fi270_xvid.avi\tfi496_xvid.avi\tno270_xvid.avi\t   no496_xvid.avi\n",
            "fi271_xvid.avi\tfi497_xvid.avi\tno271_xvid.avi\t   no497_xvid.avi\n",
            "fi272_xvid.avi\tfi498_xvid.avi\tno272_xvid.avi\t   no498_xvid.avi\n",
            "fi273_xvid.avi\tfi499_xvid.avi\tno273_xvid.avi\t   no499_xvid.avi\n",
            "fi274_xvid.avi\tfi49_xvid.avi\tno274_xvid.avi\t   no49_xvid.avi\n",
            "fi275_xvid.avi\tfi4_xvid.avi\tno275_xvid.avi\t   no4_xvid.avi\n",
            "fi276_xvid.avi\tfi500_xvid.avi\tno276_xvid.avi\t   no500_xvid.avi\n",
            "fi277_xvid.avi\tfi50_xvid.avi\tno277_xvid.avi\t   no50_xvid.avi\n",
            "fi278_xvid.avi\tfi51_xvid.avi\tno278_xvid.avi\t   no51_xvid.avi\n",
            "fi279_xvid.avi\tfi52_xvid.avi\tno279_xvid.avi\t   no52_xvid.avi\n",
            "fi27_xvid.avi\tfi53_xvid.avi\tno27_xvid.avi\t   no53_xvid.avi\n",
            "fi280_xvid.avi\tfi54_xvid.avi\tno280_xvid.avi\t   no54_xvid.avi\n",
            "fi281_xvid.avi\tfi55_xvid.avi\tno281_xvid.avi\t   no55_xvid.avi\n",
            "fi282_xvid.avi\tfi56_xvid.avi\tno282_xvid.avi\t   no56_xvid.avi\n",
            "fi283_xvid.avi\tfi57_xvid.avi\tno283_xvid.avi\t   no57_xvid.avi\n",
            "fi284_xvid.avi\tfi58_xvid.avi\tno284_xvid.avi\t   no58_xvid.avi\n",
            "fi285_xvid.avi\tfi59_xvid.avi\tno285_xvid.avi\t   no59_xvid.avi\n",
            "fi286_xvid.avi\tfi5_xvid.avi\tno286_xvid.avi\t   no5_xvid.avi\n",
            "fi287_xvid.avi\tfi60_xvid.avi\tno287_xvid.avi\t   no60_xvid.avi\n",
            "fi288_xvid.avi\tfi61_xvid.avi\tno288_xvid.avi\t   no61_xvid.avi\n",
            "fi289_xvid.avi\tfi62_xvid.avi\tno289_xvid.avi\t   no62_xvid.avi\n",
            "fi28_xvid.avi\tfi63_xvid.avi\tno28_xvid.avi\t   no63_xvid.avi\n",
            "fi290_xvid.avi\tfi64_xvid.avi\tno290_xvid.avi\t   no64_xvid.avi\n",
            "fi291_xvid.avi\tfi65_xvid.avi\tno291_xvid.avi\t   no65___xvid.avi\n",
            "fi292_xvid.avi\tfi66_xvid.avi\tno292_xvid.avi\t   no66_xvid.avi\n",
            "fi293_xvid.avi\tfi67_xvid.avi\tno293_xvid.avi\t   no67_xvid.avi\n",
            "fi294_xvid.avi\tfi68_xvid.avi\tno294_xvid.avi\t   no68_xvid.avi\n",
            "fi295_xvid.avi\tfi69_xvid.avi\tno295_xvid.avi\t   no69_xvid.avi\n",
            "fi296_xvid.avi\tfi6_xvid.avi\tno296_xvid.avi\t   no6_xvid.avi\n",
            "fi297_xvid.avi\tfi70_xvid.avi\tno297_xvid.avi\t   no70_xvid.avi\n",
            "fi298_xvid.avi\tfi71_xvid.avi\tno298_xvid.avi\t   no71_xvid.avi\n",
            "fi299_xvid.avi\tfi72_xvid.avi\tno299_xvid.avi\t   no72_xvid.avi\n",
            "fi29_xvid.avi\tfi73_xvid.avi\tno29_xvid.avi\t   no73_xvid.avi\n",
            "fi2_xvid.avi\tfi74_xvid.avi\tno2_xvid.avi\t   no74_xvid.avi\n",
            "fi300_xvid.avi\tfi75_xvid.avi\tno300_xvid.avi\t   no75_xvid.avi\n",
            "fi301_xvid.avi\tfi76_xvid.avi\tno301_xvid.avi\t   no76_xvid.avi\n",
            "fi302_xvid.avi\tfi77_xvid.avi\tno302_xvid.avi\t   no77_xvid.avi\n",
            "fi303_xvid.avi\tfi78_xvid.avi\tno303_xvid.avi\t   no78_xvid.avi\n",
            "fi304_xvid.avi\tfi79_xvid.avi\tno304_xvid.avi\t   no79_xvid.avi\n",
            "fi305_xvid.avi\tfi7_xvid.avi\tno305_xvid.avi\t   no7_xvid.avi\n",
            "fi306_xvid.avi\tfi80_xvid.avi\tno306_xvid.avi\t   no80_xvid.avi\n",
            "fi307_xvid.avi\tfi81_xvid.avi\tno307_xvid.avi\t   no81_xvid.avi\n",
            "fi308_xvid.avi\tfi82_xvid.avi\tno308_xvid.avi\t   no82_xvid.avi\n",
            "fi309_xvid.avi\tfi83_xvid.avi\tno309_xvid.avi\t   no83_xvid.avi\n",
            "fi30_xvid.avi\tfi84_xvid.avi\tno30_xvid.avi\t   no84_xvid.avi\n",
            "fi310_xvid.avi\tfi85_xvid.avi\tno310_xvid.avi\t   no85_xvid.avi\n",
            "fi311_xvid.avi\tfi86_xvid.avi\tno311_xvid.avi\t   no86_xvid.avi\n",
            "fi312_xvid.avi\tfi87_xvid.avi\tno312_xvid.avi\t   no87_xvid.avi\n",
            "fi313_xvid.avi\tfi88_xvid.avi\tno313_xvid.avi\t   no88_xvid.avi\n",
            "fi314_xvid.avi\tfi89_xvid.avi\tno314_xvid.avi\t   no89_xvid.avi\n",
            "fi315_xvid.avi\tfi8_xvid.avi\tno315_xvid.avi\t   no8_xvid.avi\n",
            "fi316_xvid.avi\tfi90_xvid.avi\tno316_xvid.avi\t   no90_xvid.avi\n",
            "fi317_xvid.avi\tfi91_xvid.avi\tno317_xvid.avi\t   no91_xvid.avi\n",
            "fi318_xvid.avi\tfi92_xvid.avi\tno318_xvid.avi\t   no92_xvid.avi\n",
            "fi319_xvid.avi\tfi93_xvid.avi\tno319_xvid.avi\t   no93_xvid.avi\n",
            "fi31_xvid.avi\tfi94_xvid.avi\tno31_xvid.avi\t   no94_xvid.avi\n",
            "fi320_xvid.avi\tfi95_xvid.avi\tno320_xvid.avi\t   no95_xvid.avi\n",
            "fi321_xvid.avi\tfi96_xvid.avi\tno321_xvid.avi\t   no96_xvid.avi\n",
            "fi322_xvid.avi\tfi97_xvid.avi\tno322_xvid.avi\t   no97_xvid.avi\n",
            "fi323_xvid.avi\tfi98_xvid.avi\tno323_xvid.avi\t   no98_xvid.avi\n",
            "fi324_xvid.avi\tfi99_xvid.avi\tno324_xvid.avi\t   no99_xvid.avi\n",
            "fi325_xvid.avi\tfi9_xvid.avi\tno325_xvid.avi\t   no9_xvid.avi\n",
            "Video no encontrado: /content/hockey_dataset/fights/fi001.mp4\n",
            "Verifica nombres con:\n",
            "ls: cannot access '/content/hockey_dataset/fights/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 1: Instalar dependencias\n",
        "!pip install -q tensorflow tensorflow-hub opencv-python-headless ultralytics scikit-learn\n",
        "!pip install --no-cache-dir -q kaggle\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Celda 2: Configurar Kaggle API (ya lo tienes, pero por si acaso)\n",
        "print(\"Si ya subiste kaggle.json, salta esto. De lo contrario, sube.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "json_file = next((f for f in uploaded.keys() if 'kaggle' in f.lower() and f.endswith('.json')), None)\n",
        "if json_file:\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp \"{json_file}\" ~/.kaggle/kaggle.json\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Celda 3: Verificar dataset (ya descargado)\n",
        "dataset_dir = '/content/hockey_dataset/data'\n",
        "if os.path.exists(dataset_dir):\n",
        "    fight_files = [f for f in os.listdir(dataset_dir) if f.startswith('fi')]\n",
        "    non_fight_files = [f for f in os.listdir(dataset_dir) if f.startswith('no')]\n",
        "    print(f\"Total videos de peleas (fi*): {len(fight_files)}\")\n",
        "    print(f\"Primeros 10: {fight_files[:10]}\")\n",
        "    print(f\"Total videos sin peleas (no*): {len(non_fight_files)}\")\n",
        "    print(f\"Primeros 10: {non_fight_files[:10]}\")\n",
        "else:\n",
        "    print(\"Dataset no encontrado. Ejecuta descarga manual si es necesario.\")\n",
        "    # Si no, fuerza descarga de nuevo\n",
        "    !rm -f hockey-fight-vidoes.zip\n",
        "    !kaggle datasets download -d yassershrief/hockey-fight-vidoes --force\n",
        "    !mkdir -p /content/hockey_dataset\n",
        "    !unzip -o hockey-fight-vidoes.zip -d /content/hockey_dataset/\n",
        "\n",
        "# Celda 4: Cargar modelos\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')\n",
        "\n",
        "# Celda 5: Funciones\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]\n",
        "    return keypoints\n",
        "\n",
        "def analyze_roles(keypoints_list, person_boxes, height):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        right_wrist = keypoints[10]  # Mano derecha [y, x, conf]\n",
        "        if right_wrist[2] > 0.3:\n",
        "            wrist_y, wrist_x = right_wrist[0], right_wrist[1]\n",
        "            for j, other_box in enumerate(person_boxes):\n",
        "                if i != j:\n",
        "                    ox, oy, ow, oh = other_box\n",
        "                    # Heurística ajustada para hockey: mano cerca del centro de la otra persona\n",
        "                    center_other_x = ox + ow / 2\n",
        "                    center_other_y = oy + oh / 2\n",
        "                    if abs(wrist_x * 192 - center_other_x) < 100 and wrist_y * height < center_other_y:\n",
        "                        roles.append((i, 'agresor'))\n",
        "                        roles.append((j, 'víctima'))\n",
        "                        return roles\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]\n",
        "\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if y_true and y_pred and len(y_true) == len(y_pred):\n",
        "        return f1_score(y_true, y_pred, labels=['agresor', 'víctima', 'desconocido'], average='weighted')\n",
        "    return 0.0\n",
        "\n",
        "# Celda 6: Procesar video\n",
        "def process_video(video_path, output_path='output_hockey.mp4', ground_truth_roles=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: No se pudo abrir {video_path}. Verifica si es AVI válido.\")\n",
        "        return None\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))  # Salida en MP4\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        r_height = 480  # Altura redimensionada\n",
        "\n",
        "        # Detectar personas\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if int(box.cls) == 0:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Poses\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0 and w > 50 and h > 100:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))\n",
        "\n",
        "        # Roles\n",
        "        roles = analyze_roles(keypoints_list, person_boxes, r_height)\n",
        "        all_pred_roles.append(roles)\n",
        "\n",
        "        # Dibujar\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Box verde\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx = int(kp[1] * w + x)\n",
        "                    ky = int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 3, (255, 255, 0), -1)  # Keypoints amarillos\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Procesados {frame_count} frames...\")\n",
        "        if frame_count >= 300:  # Limite para pruebas\n",
        "            print(\"Procesamiento limitado a 300 frames para prueba rápida.\")\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0] if all_pred_roles else [])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"¡Listo! Video guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Celda 7: Procesar un video de ejemplo\n",
        "video_path = '/content/hockey_dataset/data/fi1_xvid.avi'  # Video de pelea (ajusta si quieres otro, ej. fi2_xvid.avi)\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo; ajusta si tienes anotaciones\n",
        "\n",
        "if os.path.exists(video_path):\n",
        "    output_path = process_video(video_path, 'output_hockey.mp4', ground_truth_roles)\n",
        "    if output_path:\n",
        "        files.download(output_path)\n",
        "else:\n",
        "    print(f\"Video no encontrado: {video_path}\")\n",
        "    print(\"Verifica nombres con:\")\n",
        "    !ls /content/hockey_dataset/data/ | grep fi | head -10  # Primeros 10 fi*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bi6kalRQNuj",
        "outputId": "288284c8-9a19-476f-df9d-12bb65ff1422"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si ya subiste kaggle.json, salta esto. De lo contrario, sube.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1a3c7979-daa4-41e6-961f-784bb3a1e40d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1a3c7979-daa4-41e6-961f-784bb3a1e40d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (4).json\n",
            "Total videos de peleas (fi*): 500\n",
            "Primeros 10: ['fi289_xvid.avi', 'fi43_xvid.avi', 'fi48_xvid.avi', 'fi229_xvid.avi', 'fi20_xvid.avi', 'fi39_xvid.avi', 'fi327_xvid.avi', 'fi142_xvid.avi', 'fi4_xvid.avi', 'fi242_xvid.avi']\n",
            "Total videos sin peleas (no*): 500\n",
            "Primeros 10: ['no142__xvid.avi', 'no462_xvid.avi', 'no414_xvid.avi', 'no285_xvid.avi', 'no493_xvid.avi', 'no179_xvid.avi', 'no365_xvid.avi', 'no221_xvid.avi', 'no226_xvid.avi', 'no326_xvid.avi']\n",
            "\n",
            "0: 480x640 2 persons, 83.8ms\n",
            "Speed: 1.9ms preprocess, 83.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 persons, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 persons, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.2ms\n",
            "Speed: 1.5ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 refrigerator, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.2ms\n",
            "Speed: 2.0ms preprocess, 6.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.3ms\n",
            "Speed: 2.2ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.0ms\n",
            "Speed: 2.0ms preprocess, 6.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 2 cats, 1 tv, 7.4ms\n",
            "Speed: 2.7ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 7.3ms\n",
            "Speed: 1.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.5ms\n",
            "Speed: 2.3ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 1 person, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 persons, 6.7ms\n",
            "Speed: 2.1ms preprocess, 6.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 persons, 1 handbag, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "F1-Score para roles: 0.0000\n",
            "¡Listo! Video guardado en: output_hockey.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e674b167-5acd-4af0-9690-2ea37f337e60\", \"output_hockey.mp4\", 856103)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 1-3: Asume que ya tienes el dataset descargado. Si no, ejecuta las celdas anteriores para descargar.\n",
        "\n",
        "# Celda 4: Cargar modelos (si no lo hiciste)\n",
        "movenet_model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = movenet_model.signatures['serving_default']\n",
        "yolo = YOLO('yolov8n.pt')\n",
        "\n",
        "# Celda 5: Funciones con heurística mejorada\n",
        "def preprocess_frame(frame):\n",
        "    img = cv2.resize(frame, (192, 192))\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.int32)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "def detect_pose(frame):\n",
        "    input_image = preprocess_frame(frame)\n",
        "    outputs = movenet(input_image)\n",
        "    keypoints = outputs['output_0'].numpy()[0, 0]\n",
        "    return keypoints\n",
        "\n",
        "def analyze_roles(keypoints_list, person_boxes, height):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        # Verificar ambas manos (keypoint 9: izquierda, 10: derecha)\n",
        "        hands = [keypoints[9], keypoints[10]]  # [y, x, conf]\n",
        "        for hand in hands:\n",
        "            if hand[2] > 0.3:  # Confianza suficiente\n",
        "                hand_y, hand_x = hand[0], hand[1]\n",
        "                if hand_y < 0.5:  # Mano \"alta\" (y bajo en coordenadas normalizadas)\n",
        "                    for j, other_box in enumerate(person_boxes):\n",
        "                        if i != j:\n",
        "                            ox, oy, ow, oh = other_box\n",
        "                            center_other_x = ox + ow / 2\n",
        "                            center_other_y = oy + oh / 2\n",
        "                            dist_x = abs(hand_x * 192 - center_other_x)\n",
        "                            dist_y = abs(hand_y * height - center_other_y)\n",
        "                            if dist_x < 80 and dist_y < 80:  # Cerca en x e y\n",
        "                                print(f\"Detectado agresor {i} (mano en y={hand_y:.2f}, dist_x={dist_x:.2f}, dist_y={dist_y:.2f}) cerca de víctima {j}\")\n",
        "                                roles.append((i, 'agresor'))\n",
        "                                roles.append((j, 'víctima'))\n",
        "                                return roles\n",
        "    print(\"No se detectó interacción: manos bajas o lejanas.\")\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]\n",
        "\n",
        "def calculate_metrics(true_roles, pred_roles):\n",
        "    y_true = [r for _, r in true_roles]\n",
        "    y_pred = [r for _, r in pred_roles]\n",
        "    if y_true and y_pred and len(y_true) == len(y_pred):\n",
        "        return f1_score(y_true, y_pred, labels=['agresor', 'víctima', 'desconocido'], average='weighted')\n",
        "    return 0.0\n",
        "\n",
        "# Celda 6: Procesar video\n",
        "def process_video(video_path, output_path='output_hockey.mp4', ground_truth_roles=None):\n",
        "    # Opcional: Convertir AVI a MP4 si cv2 falla (descomenta si necesario)\n",
        "    # !ffmpeg -i \"{video_path}\" temp.mp4 -y\n",
        "    # video_path = 'temp.mp4'\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: No se pudo abrir {video_path}. Prueba con ffmpeg para convertir.\")\n",
        "        return None\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        r_height = 480\n",
        "\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if int(box.cls) == 0:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0 and w > 50 and h > 100:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))\n",
        "\n",
        "        roles = analyze_roles(keypoints_list, person_boxes, r_height)\n",
        "        all_pred_roles.append(roles)\n",
        "\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in roles if idx == i), 'desconocido')\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx = int(kp[1] * w + x)\n",
        "                    ky = int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 3, (255, 255, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Procesados {frame_count} frames...\")\n",
        "        if frame_count >= 300:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0] if all_pred_roles else [])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"¡Listo! Video guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Celda 7: Procesar\n",
        "video_path = '/content/hockey_dataset/data/fi1_xvid.avi'  # Prueba con este o cambia a fi10_xvid.avi si no detecta\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo\n",
        "\n",
        "output_path = process_video(video_path, 'output_hockey_improved.mp4', ground_truth_roles)\n",
        "if output_path:\n",
        "    files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QdFzlAe7Qvn6",
        "outputId": "28df901b-95b0-4d05-d866-6f4200be2aee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 7.7ms\n",
            "Speed: 2.3ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 3 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 3 persons, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 3 persons, 6.7ms\n",
            "Speed: 2.1ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 1 refrigerator, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.2ms\n",
            "Speed: 1.3ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 7.5ms\n",
            "Speed: 1.7ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 2 cats, 1 tv, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano en y=0.44, dist_x=2.26, dist_y=28.08) cerca de víctima 1\n",
            "\n",
            "0: 480x640 2 persons, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 1 person, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 5.9ms\n",
            "Speed: 1.2ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 1 person, 6.0ms\n",
            "Speed: 2.1ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 3 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 3 persons, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 2 persons, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "\n",
            "0: 480x640 3 persons, 1 handbag, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó interacción: manos bajas o lejanas.\n",
            "F1-Score para roles: 0.0000\n",
            "¡Listo! Video guardado en: output_hockey_improved.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2089853c-4b9c-4a9a-b02a-cf0ac0db17be\", \"output_hockey_improved.mp4\", 856103)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asume que ya tienes las otras funciones (preprocess_frame, detect_pose, calculate_metrics)\n",
        "\n",
        "def analyze_roles(keypoints_list, person_boxes, height, mag_mean):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        hands = [keypoints[9], keypoints[10]]  # Izquierda y derecha\n",
        "        for hand in hands:\n",
        "            if hand[2] > 0.3:\n",
        "                hand_y, hand_x = hand[0], hand[1]\n",
        "                if hand_y < 0.6:  # Mano semi-alta\n",
        "                    for j, other_box in enumerate(person_boxes):\n",
        "                        if i != j:\n",
        "                            ox, oy, ow, oh = other_box\n",
        "                            center_other_x = ox + ow / 2\n",
        "                            center_other_y = oy + oh / 2\n",
        "                            dist_x = abs(hand_x * 192 - center_other_x)\n",
        "                            dist_y = abs(hand_y * height - center_other_y)\n",
        "                            if dist_x < 100 and dist_y < 100:\n",
        "                                print(f\"Detectado agresor {i} (mano y={hand_y:.2f}, dist_x={dist_x:.2f}, dist_y={dist_y:.2f}, mag={mag_mean:.2f}) cerca de víctima {j}\")\n",
        "                                return [(i, 'agresor'), (j, 'víctima')]\n",
        "    if mag_mean > 5:  # Movimiento alto: fuerza \"agresor\" si hay proximidad general\n",
        "        if len(person_boxes) >= 2:\n",
        "            dist_between = abs(person_boxes[0][0] - person_boxes[1][0])\n",
        "            if dist_between < 150:  # Personas cercanas con movimiento\n",
        "                print(f\"Movimiento alto ({mag_mean:.2f}) y proximidad: asignando agresor 0, víctima 1\")\n",
        "                return [(0, 'agresor'), (1, 'víctima')]\n",
        "    print(f\"No se detectó: manos bajas/lejanas, mag={mag_mean:.2f}\")\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]\n",
        "\n",
        "def process_video(video_path, output_path='output_hockey_persistent.mp4', ground_truth_roles=None, persistence_frames=5):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error al abrir {video_path}\")\n",
        "        return None\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))\n",
        "\n",
        "    frame_count = 0\n",
        "    all_pred_roles = []\n",
        "    prev_gray = None\n",
        "    last_roles = None\n",
        "    persistence_counter = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        r_height = 480\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Optical Flow\n",
        "        mag_mean = 0\n",
        "        if prev_gray is not None:\n",
        "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "            mag_mean = np.mean(mag)\n",
        "\n",
        "        prev_gray = gray\n",
        "\n",
        "        # Detectar personas\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if int(box.cls) == 0:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Poses\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0 and w > 50 and h > 100:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))\n",
        "\n",
        "        # Roles\n",
        "        current_roles = analyze_roles(keypoints_list, person_boxes, r_height, mag_mean)\n",
        "\n",
        "        # Persistencia\n",
        "        if any(r != 'desconocido' for _, r in current_roles):\n",
        "            last_roles = current_roles\n",
        "            persistence_counter = persistence_frames\n",
        "        elif persistence_counter > 0:\n",
        "            current_roles = last_roles\n",
        "            persistence_counter -= 1\n",
        "            print(f\"Persistiendo roles por {persistence_counter} frames más\")\n",
        "        else:\n",
        "            last_roles = None\n",
        "\n",
        "        all_pred_roles.append(current_roles)\n",
        "\n",
        "        # Dibujar\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in current_roles if idx == i), 'desconocido')\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx = int(kp[1] * w + x)\n",
        "                    ky = int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 3, (255, 255, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Procesados {frame_count} frames...\")\n",
        "        if frame_count >= 300:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, all_pred_roles[0] if all_pred_roles else [])\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"¡Listo! Video guardado en: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Uso: Cambia video si quieres\n",
        "video_path = '/content/hockey_dataset/data/fi1_xvid.avi'\n",
        "output_path = process_video(video_path, 'output_hockey_persistent.mp4', ground_truth_roles)\n",
        "if output_path:\n",
        "    files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pZNVv3i9RRxt",
        "outputId": "47b4483c-fb4f-4bd6-b786-3429d8b230d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.00\n",
            "\n",
            "0: 480x640 2 persons, 13.8ms\n",
            "Speed: 3.9ms preprocess, 13.8ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.76\n",
            "\n",
            "0: 480x640 2 persons, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.91\n",
            "\n",
            "0: 480x640 3 persons, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "\n",
            "0: 480x640 3 persons, 19.4ms\n",
            "Speed: 3.0ms preprocess, 19.4ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.84\n",
            "\n",
            "0: 480x640 2 persons, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.23\n",
            "\n",
            "0: 480x640 3 persons, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.15\n",
            "\n",
            "0: 480x640 1 person, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.62\n",
            "\n",
            "0: 480x640 1 person, 28.7ms\n",
            "Speed: 7.7ms preprocess, 28.7ms inference, 8.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "\n",
            "0: 480x640 1 person, 24.4ms\n",
            "Speed: 3.4ms preprocess, 24.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.06\n",
            "\n",
            "0: 480x640 1 person, 1 refrigerator, 6.8ms\n",
            "Speed: 2.1ms preprocess, 6.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.50\n",
            "\n",
            "0: 480x640 1 person, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.35\n",
            "\n",
            "0: 480x640 2 persons, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.65\n",
            "\n",
            "0: 480x640 1 person, 7.3ms\n",
            "Speed: 2.1ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.13\n",
            "\n",
            "0: 480x640 2 persons, 7.0ms\n",
            "Speed: 2.1ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.99\n",
            "\n",
            "0: 480x640 1 person, 8.0ms\n",
            "Speed: 2.6ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.23\n",
            "\n",
            "0: 480x640 2 persons, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.95\n",
            "\n",
            "0: 480x640 2 persons, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.52\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.3ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.76\n",
            "\n",
            "0: 480x640 1 person, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.94\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.50\n",
            "\n",
            "0: 480x640 1 person, 2 cats, 1 tv, 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.15\n",
            "\n",
            "0: 480x640 2 persons, 7.8ms\n",
            "Speed: 2.7ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.44, dist_x=2.26, dist_y=28.08, mag=4.93) cerca de víctima 1\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.59\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 2 persons, 7.2ms\n",
            "Speed: 2.4ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.46\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=6.95\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.22\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 2 persons, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.19\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 2 persons, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.92\n",
            "\n",
            "0: 480x640 1 person, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.39\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 1 person, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.46\n",
            "\n",
            "0: 480x640 1 person, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.16\n",
            "\n",
            "0: 480x640 2 persons, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.08\n",
            "\n",
            "0: 480x640 1 person, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.26\n",
            "\n",
            "0: 480x640 2 persons, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.30\n",
            "\n",
            "0: 480x640 2 persons, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.30\n",
            "\n",
            "0: 480x640 3 persons, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.68\n",
            "\n",
            "0: 480x640 3 persons, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.11\n",
            "\n",
            "0: 480x640 2 persons, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.39\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 2.6ms preprocess, 6.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.23\n",
            "\n",
            "0: 480x640 3 persons, 1 handbag, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.36\n",
            "F1-Score para roles: 0.0000\n",
            "¡Listo! Video guardado en: output_hockey_persistent.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7873c9c3-93a1-4b13-a2e8-63e312c113e8\", \"output_hockey_persistent.mp4\", 850677)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "def analyze_roles(keypoints_list, person_boxes, height, mag_mean):\n",
        "    roles = []\n",
        "    for i, (keypoints, box) in enumerate(zip(keypoints_list, person_boxes)):\n",
        "        hands = [keypoints[9], keypoints[10]]  # Izquierda, derecha\n",
        "        for hand in hands:\n",
        "            if hand[2] > 0.3:\n",
        "                hand_y, hand_x = hand[0], hand[1]\n",
        "                if hand_y < 0.6:\n",
        "                    for j, other_box in enumerate(person_boxes):\n",
        "                        if i != j:\n",
        "                            ox, oy, ow, oh = other_box\n",
        "                            center_other_x = ox + ow / 2\n",
        "                            center_other_y = oy + oh / 2\n",
        "                            dist_x = abs(hand_x * 192 - center_other_x)\n",
        "                            dist_y = abs(hand_y * height - center_other_y)\n",
        "                            if dist_x < 120 and dist_y < 120:\n",
        "                                print(f\"Detectado agresor {i} (mano y={hand_y:.2f}, dist_x={dist_x:.2f}, dist_y={dist_y:.2f}, mag={mag_mean:.2f}) cerca de víctima {j}\")\n",
        "                                return [(i, 'agresor'), (j, 'víctima')]\n",
        "    if mag_mean > 4 and len(person_boxes) >= 2:\n",
        "        dist_between = abs(person_boxes[0][0] - person_boxes[1][0])\n",
        "        if dist_between < 150:\n",
        "            print(f\"Movimiento alto (mag={mag_mean:.2f}) y proximidad: asignando agresor 0, víctima 1\")\n",
        "            return [(0, 'agresor'), (1, 'víctima')]\n",
        "    print(f\"No se detectó: manos bajas/lejanas, mag={mag_mean:.2f}\")\n",
        "    return [(i, 'desconocido') for i in range(len(keypoints_list))]\n",
        "\n",
        "def process_video(video_path, output_path, ground_truth_roles=None, persistence_frames=7):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error al abrir {video_path}\")\n",
        "        return None, 0, 0\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))\n",
        "\n",
        "    frame_count = 0\n",
        "    agresor_count = 0\n",
        "    victima_count = 0\n",
        "    prev_gray = None\n",
        "    last_roles = None\n",
        "    persistence_counter = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        r_height = 480\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Optical Flow\n",
        "        mag_mean = 0\n",
        "        if prev_gray is not None:\n",
        "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "            mag_mean = np.mean(mag)\n",
        "\n",
        "        prev_gray = gray\n",
        "\n",
        "        # Detectar personas\n",
        "        results = yolo(frame)\n",
        "        person_boxes = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                if int(box.cls) == 0:  # Solo personas\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                    person_boxes.append((x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "        # Poses\n",
        "        keypoints_list = []\n",
        "        for box in person_boxes:\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            person_crop = frame[max(0, y):y+h, max(0, x):x+w]\n",
        "            if person_crop.size > 0 and w > 50 and h > 100:\n",
        "                keypoints = detect_pose(person_crop)\n",
        "                keypoints_list.append(keypoints)\n",
        "            else:\n",
        "                keypoints_list.append(np.zeros((17, 3)))\n",
        "\n",
        "        # Roles\n",
        "        current_roles = analyze_roles(keypoints_list, person_boxes, r_height, mag_mean)\n",
        "\n",
        "        # Persistencia\n",
        "        if any(r != 'desconocido' for _, r in current_roles):\n",
        "            last_roles = current_roles\n",
        "            persistence_counter = persistence_frames\n",
        "            agresor_count += 1 if any(r == 'agresor' for _, r in current_roles) else 0\n",
        "            victima_count += 1 if any(r == 'víctima' for _, r in current_roles) else 0\n",
        "        elif persistence_counter > 0:\n",
        "            current_roles = last_roles\n",
        "            persistence_counter -= 1\n",
        "            agresor_count += 1 if any(r == 'agresor' for _, r in current_roles) else 0\n",
        "            victima_count += 1 if any(r == 'víctima' for _, r in current_roles) else 0\n",
        "            print(f\"Persistiendo roles por {persistence_counter} frames más\")\n",
        "        else:\n",
        "            last_roles = None\n",
        "\n",
        "        # Dibujar\n",
        "        for i, (box, keypoints) in enumerate(zip(person_boxes, keypoints_list)):\n",
        "            x, y, w, h = [int(v) for v in box]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            role = next((r for idx, r in current_roles if idx == i), 'desconocido')\n",
        "            color = (0, 0, 255) if role == 'agresor' else (255, 0, 0) if role == 'víctima' else (128, 128, 128)\n",
        "            cv2.putText(frame, role.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "            for kp in keypoints:\n",
        "                if kp[2] > 0.3:\n",
        "                    kx = int(kp[1] * w + x)\n",
        "                    ky = int(kp[0] * h + y)\n",
        "                    cv2.circle(frame, (kx, ky), 3, (255, 255, 0), -1)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Procesados {frame_count} frames...\")\n",
        "        if frame_count >= 300:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if ground_truth_roles:\n",
        "        f1 = calculate_metrics(ground_truth_roles, current_roles)\n",
        "        print(f\"F1-Score para roles: {f1:.4f}\")\n",
        "\n",
        "    print(f\"Video: {video_path}\")\n",
        "    print(f\"Frames con agresor: {agresor_count}\")\n",
        "    print(f\"Frames con víctima: {victima_count}\")\n",
        "    print(f\"¡Listo! Video guardado en: {output_path}\")\n",
        "    return output_path, agresor_count, victima_count\n",
        "\n",
        "# Procesar múltiples videos\n",
        "dataset_dir = '/content/hockey_dataset/data'\n",
        "videos_to_test = [\n",
        "    'fi1_xvid.avi',\n",
        "    'fi2_xvid.avi',\n",
        "    'fi3_xvid.avi',\n",
        "    'fi4_xvid.avi',\n",
        "    'fi5_xvid.avi',\n",
        "    'no1_xvid.avi'  # Control (sin pelea)\n",
        "]\n",
        "ground_truth_roles = [(0, 'agresor'), (1, 'víctima')]  # Ejemplo, ajusta si tienes anotaciones reales\n",
        "\n",
        "report = []\n",
        "for video in videos_to_test:\n",
        "    video_path = os.path.join(dataset_dir, video)\n",
        "    output_path = f'output_{video.replace(\".avi\", \".mp4\")}'\n",
        "    if os.path.exists(video_path):\n",
        "        print(f\"\\nProcesando {video}...\")\n",
        "        result, agresor_count, victima_count = process_video(video_path, output_path, ground_truth_roles)\n",
        "        if result:\n",
        "            report.append((video, agresor_count, victima_count, result))\n",
        "            files.download(result)\n",
        "    else:\n",
        "        print(f\"Video no encontrado: {video_path}\")\n",
        "\n",
        "# Resumen\n",
        "print(\"\\nReporte Final:\")\n",
        "for video, agresor_count, victima_count, output in report:\n",
        "    print(f\"{video}: Agresor en {agresor_count} frames, Víctima en {victima_count} frames, Output: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NbawbQLiRu6_",
        "outputId": "ab3d6ca0-85bd-4e80-fe71-459bc85aad86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Procesando fi1_xvid.avi...\n",
            "\n",
            "0: 480x640 2 persons, 23.7ms\n",
            "Speed: 5.5ms preprocess, 23.7ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.00\n",
            "\n",
            "0: 480x640 2 persons, 25.2ms\n",
            "Speed: 2.0ms preprocess, 25.2ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.76\n",
            "\n",
            "0: 480x640 2 persons, 24.9ms\n",
            "Speed: 8.0ms preprocess, 24.9ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.91\n",
            "\n",
            "0: 480x640 3 persons, 32.1ms\n",
            "Speed: 5.3ms preprocess, 32.1ms inference, 15.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "\n",
            "0: 480x640 3 persons, 45.1ms\n",
            "Speed: 3.8ms preprocess, 45.1ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.84\n",
            "\n",
            "0: 480x640 2 persons, 36.9ms\n",
            "Speed: 10.4ms preprocess, 36.9ms inference, 11.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.23\n",
            "\n",
            "0: 480x640 3 persons, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.15\n",
            "\n",
            "0: 480x640 1 person, 28.4ms\n",
            "Speed: 3.4ms preprocess, 28.4ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.62\n",
            "\n",
            "0: 480x640 1 person, 37.4ms\n",
            "Speed: 3.8ms preprocess, 37.4ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "\n",
            "0: 480x640 1 person, 25.3ms\n",
            "Speed: 6.2ms preprocess, 25.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.06\n",
            "\n",
            "0: 480x640 1 person, 1 refrigerator, 22.4ms\n",
            "Speed: 8.0ms preprocess, 22.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.50\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.35\n",
            "\n",
            "0: 480x640 2 persons, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=4.65) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 1 person, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.13\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 2 persons, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.99\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.6ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.23\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 2 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.95\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 2 persons, 6.8ms\n",
            "Speed: 2.5ms preprocess, 6.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.52\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 1 person, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.76\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.5ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.94\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 1 person, 1 dog, 6.7ms\n",
            "Speed: 2.4ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.50\n",
            "\n",
            "0: 480x640 1 person, 2 cats, 1 tv, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.15\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.44, dist_x=2.26, dist_y=28.08, mag=4.93) cerca de víctima 1\n",
            "\n",
            "0: 480x640 2 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.59\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 2 persons, 6.8ms\n",
            "Speed: 2.1ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.46\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 1 person, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=6.95\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 1 person, 6.8ms\n",
            "Speed: 2.2ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.22\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 2 persons, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.19\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 2 persons, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.92\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.39\n",
            "Persistiendo roles por 0 frames más\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.4ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.46\n",
            "\n",
            "0: 480x640 1 person, 6.9ms\n",
            "Speed: 2.5ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.16\n",
            "\n",
            "0: 480x640 2 persons, 7.6ms\n",
            "Speed: 2.8ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.08\n",
            "\n",
            "0: 480x640 1 person, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.26\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.30\n",
            "\n",
            "0: 480x640 2 persons, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.30\n",
            "\n",
            "0: 480x640 3 persons, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=4.68) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 3 persons, 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.11\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 2 persons, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.39\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 2 persons, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.23\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 3 persons, 1 handbag, 7.0ms\n",
            "Speed: 2.3ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.36\n",
            "Persistiendo roles por 3 frames más\n",
            "F1-Score para roles: 1.0000\n",
            "Video: /content/hockey_dataset/data/fi1_xvid.avi\n",
            "Frames con agresor: 21\n",
            "Frames con víctima: 21\n",
            "¡Listo! Video guardado en: output_fi1_xvid.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fcb72f83-2ed1-4515-8291-4bc69faeed26\", \"output_fi1_xvid.mp4\", 851761)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Procesando fi2_xvid.avi...\n",
            "\n",
            "0: 480x640 2 persons, 6.6ms\n",
            "Speed: 2.0ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.00\n",
            "\n",
            "0: 480x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=5.48) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 3 persons, 6.8ms\n",
            "Speed: 2.5ms preprocess, 6.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=5.98) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=5.22\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 2 persons, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.50\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.08\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 2 persons, 1 dog, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.13\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.5ms preprocess, 7.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.26\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 2 persons, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.87\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 2 persons, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.60\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.0ms\n",
            "Speed: 2.7ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.31\n",
            "\n",
            "0: 480x640 3 persons, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.99\n",
            "\n",
            "0: 480x640 3 persons, 7.4ms\n",
            "Speed: 1.9ms preprocess, 7.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.93\n",
            "\n",
            "0: 480x640 2 persons, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.93\n",
            "\n",
            "0: 480x640 3 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.22\n",
            "\n",
            "0: 480x640 3 persons, 7.3ms\n",
            "Speed: 2.7ms preprocess, 7.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.01\n",
            "\n",
            "0: 480x640 2 persons, 1 dog, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.06\n",
            "\n",
            "0: 480x640 3 persons, 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.30, dist_x=87.36, dist_y=95.32, mag=2.44) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 7.0ms\n",
            "Speed: 2.6ms preprocess, 7.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.72\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 3 persons, 13.5ms\n",
            "Speed: 3.7ms preprocess, 13.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.80\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.0ms\n",
            "Speed: 2.2ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.71\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 3 persons, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.49\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.9ms\n",
            "Speed: 3.0ms preprocess, 7.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.51\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 3 persons, 6.9ms\n",
            "Speed: 2.6ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.12\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.23\n",
            "\n",
            "0: 480x640 3 persons, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.04\n",
            "\n",
            "0: 480x640 3 persons, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.69\n",
            "\n",
            "0: 480x640 3 persons, 7.4ms\n",
            "Speed: 2.3ms preprocess, 7.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=4.32) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 4 persons, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=4.19) y proximidad: asignando agresor 0, víctima 1\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 3 persons, 7.0ms\n",
            "Speed: 2.5ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=4.19) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 3 persons, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Movimiento alto (mag=4.46) y proximidad: asignando agresor 0, víctima 1\n",
            "\n",
            "0: 480x640 3 persons, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 2 (mano y=0.28, dist_x=61.64, dist_y=101.01, mag=3.34) cerca de víctima 0\n",
            "\n",
            "0: 480x640 3 persons, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.92\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 3 persons, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.24\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.47\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 5 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.92\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.64\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 3 persons, 1 backpack, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=4.23\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 3 persons, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.50\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 4 persons, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.75\n",
            "F1-Score para roles: 0.0000\n",
            "Video: /content/hockey_dataset/data/fi2_xvid.avi\n",
            "Frames con agresor: 29\n",
            "Frames con víctima: 29\n",
            "¡Listo! Video guardado en: output_fi2_xvid.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4e156d2a-c98c-4186-9636-185b0668338c\", \"output_fi2_xvid.mp4\", 1160550)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Procesando fi3_xvid.avi...\n",
            "\n",
            "0: 480x640 3 persons, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.00\n",
            "\n",
            "0: 480x640 3 persons, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.82\n",
            "\n",
            "0: 480x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.35, dist_x=84.01, dist_y=65.48, mag=1.90) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.35, dist_x=83.52, dist_y=63.96, mag=2.00) cerca de víctima 0\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.26\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.55, dist_x=72.22, dist_y=29.13, mag=2.68) cerca de víctima 0\n",
            "\n",
            "0: 480x640 3 persons, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.30\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.55\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.5ms\n",
            "Speed: 2.3ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.40\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 3 persons, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.00\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.4ms\n",
            "Speed: 2.0ms preprocess, 7.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.72\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.4ms preprocess, 7.2ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.54\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.63\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.4ms\n",
            "Speed: 2.3ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.55\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.16\n",
            "\n",
            "0: 480x640 3 persons, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.07\n",
            "\n",
            "0: 480x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.89\n",
            "\n",
            "0: 480x640 3 persons, 1 backpack, 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 2 (mano y=0.45, dist_x=65.76, dist_y=79.61, mag=1.86) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 1 backpack, 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.69\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 2 (mano y=0.34, dist_x=18.31, dist_y=72.83, mag=1.79) cerca de víctima 1\n",
            "\n",
            "0: 480x640 4 persons, 6.9ms\n",
            "Speed: 2.8ms preprocess, 6.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 2 (mano y=0.29, dist_x=3.41, dist_y=92.04, mag=2.20) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 7.0ms\n",
            "Speed: 2.2ms preprocess, 7.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.20\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.3ms\n",
            "Speed: 2.1ms preprocess, 7.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.34, dist_x=48.72, dist_y=61.98, mag=2.24) cerca de víctima 2\n",
            "\n",
            "0: 480x640 4 persons, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.51\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.24\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 5 persons, 7.0ms\n",
            "Speed: 2.4ms preprocess, 7.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.91\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 5 persons, 7.4ms\n",
            "Speed: 1.9ms preprocess, 7.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.64\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.47\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 2 (mano y=0.53, dist_x=18.37, dist_y=37.90, mag=1.40) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.25\n",
            "Persistiendo roles por 6 frames más\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.92\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 5 persons, 1 backpack, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.87\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.5ms\n",
            "Speed: 2.2ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.26\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 4 persons, 1 backpack, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.34\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.26, dist_x=15.80, dist_y=31.02, mag=1.51) cerca de víctima 2\n",
            "\n",
            "0: 480x640 3 persons, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.34, dist_x=118.06, dist_y=101.67, mag=1.47) cerca de víctima 2\n",
            "\n",
            "0: 480x640 3 persons, 1 backpack, 7.4ms\n",
            "Speed: 1.9ms preprocess, 7.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.48\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.34\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 3 persons, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.31\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 3 persons, 1 backpack, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.27\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 1 backpack, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.13\n",
            "Persistiendo roles por 2 frames más\n",
            "F1-Score para roles: 1.0000\n",
            "Video: /content/hockey_dataset/data/fi3_xvid.avi\n",
            "Frames con agresor: 35\n",
            "Frames con víctima: 35\n",
            "¡Listo! Video guardado en: output_fi3_xvid.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e36063cb-c544-45c0-a196-2766fd451c33\", \"output_fi3_xvid.mp4\", 1355830)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Procesando fi4_xvid.avi...\n",
            "\n",
            "0: 480x640 5 persons, 6.9ms\n",
            "Speed: 2.3ms preprocess, 6.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 3 (mano y=0.48, dist_x=37.12, dist_y=57.52, mag=0.00) cerca de víctima 1\n",
            "\n",
            "0: 480x640 4 persons, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.90\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.97\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 5 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.05\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.0ms\n",
            "Speed: 2.6ms preprocess, 7.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.31, dist_x=83.03, dist_y=104.73, mag=1.96) cerca de víctima 1\n",
            "\n",
            "0: 480x640 4 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.17\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 3 (mano y=0.46, dist_x=22.33, dist_y=65.21, mag=3.12) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 7.4ms\n",
            "Speed: 2.2ms preprocess, 7.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.42\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 6.8ms\n",
            "Speed: 2.7ms preprocess, 6.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.38\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.41\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.08\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.51\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.82\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.57\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.5ms\n",
            "Speed: 1.5ms preprocess, 9.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.21\n",
            "\n",
            "0: 480x640 4 persons, 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 3 (mano y=0.59, dist_x=75.55, dist_y=80.39, mag=1.18) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.26\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 5 persons, 6.9ms\n",
            "Speed: 2.7ms preprocess, 6.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.40\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 9.7ms\n",
            "Speed: 1.5ms preprocess, 9.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.20, dist_x=31.55, dist_y=107.40, mag=1.64) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.62\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.45\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.29\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.31\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.23\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.33, dist_x=51.87, dist_y=100.24, mag=1.31) cerca de víctima 2\n",
            "\n",
            "0: 480x640 4 persons, 1 fire hydrant, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.25\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.0ms\n",
            "Speed: 2.7ms preprocess, 8.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.06\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 5 persons, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.47\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.60\n",
            "Persistiendo roles por 3 frames más\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 4 persons, 14.2ms\n",
            "Speed: 1.6ms preprocess, 14.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.42\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 4 persons, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.28\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 4 persons, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.15\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 4 persons, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.27\n",
            "\n",
            "0: 480x640 4 persons, 1 backpack, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.39, dist_x=52.20, dist_y=102.86, mag=1.29) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 3 (mano y=0.40, dist_x=49.13, dist_y=97.96, mag=1.27) cerca de víctima 0\n",
            "\n",
            "0: 480x640 4 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.13\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.14\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.32\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.40\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 4 persons, 12.6ms\n",
            "Speed: 2.9ms preprocess, 12.6ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.68\n",
            "Persistiendo roles por 2 frames más\n",
            "F1-Score para roles: 1.0000\n",
            "Video: /content/hockey_dataset/data/fi4_xvid.avi\n",
            "Frames con agresor: 39\n",
            "Frames con víctima: 39\n",
            "¡Listo! Video guardado en: output_fi4_xvid.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_237e1449-5855-4502-b75e-9afb558addc4\", \"output_fi4_xvid.mp4\", 1339895)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Procesando fi5_xvid.avi...\n",
            "\n",
            "0: 480x640 2 persons, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.00\n",
            "\n",
            "0: 480x640 2 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.98\n",
            "\n",
            "0: 480x640 3 persons, 7.3ms\n",
            "Speed: 2.2ms preprocess, 7.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.09\n",
            "\n",
            "0: 480x640 3 persons, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.12\n",
            "\n",
            "0: 480x640 2 persons, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.51\n",
            "\n",
            "0: 480x640 3 persons, 1 handbag, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.80\n",
            "\n",
            "0: 480x640 3 persons, 7.1ms\n",
            "Speed: 2.6ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.95\n",
            "\n",
            "0: 480x640 3 persons, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.08\n",
            "\n",
            "0: 480x640 3 persons, 6.9ms\n",
            "Speed: 2.7ms preprocess, 6.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.94\n",
            "\n",
            "0: 480x640 3 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.97\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.4ms preprocess, 7.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.00\n",
            "\n",
            "0: 480x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.97\n",
            "\n",
            "0: 480x640 3 persons, 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.98\n",
            "\n",
            "0: 480x640 5 persons, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.12\n",
            "\n",
            "0: 480x640 4 persons, 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.25\n",
            "\n",
            "0: 480x640 4 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.47\n",
            "\n",
            "0: 480x640 4 persons, 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.53\n",
            "\n",
            "0: 480x640 5 persons, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.53\n",
            "\n",
            "0: 480x640 4 persons, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.41\n",
            "\n",
            "0: 480x640 3 persons, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.47\n",
            "\n",
            "0: 480x640 4 persons, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.34, dist_x=80.16, dist_y=108.01, mag=2.69) cerca de víctima 3\n",
            "\n",
            "0: 480x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.32, dist_x=76.26, dist_y=114.30, mag=2.95) cerca de víctima 3\n",
            "\n",
            "0: 480x640 4 persons, 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.14\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.38\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.71\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.34, dist_x=50.55, dist_y=102.86, mag=3.25) cerca de víctima 3\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.38\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.71\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.6ms\n",
            "Speed: 2.3ms preprocess, 7.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.58\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.78\n",
            "Persistiendo roles por 3 frames más\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 4 persons, 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.66\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.83\n",
            "Persistiendo roles por 1 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "Persistiendo roles por 0 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.5ms\n",
            "Speed: 2.0ms preprocess, 7.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.53\n",
            "\n",
            "0: 480x640 4 persons, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.42\n",
            "\n",
            "0: 480x640 4 persons, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.53\n",
            "\n",
            "0: 480x640 4 persons, 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.54\n",
            "\n",
            "0: 480x640 5 persons, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.18\n",
            "\n",
            "0: 480x640 4 persons, 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.00\n",
            "\n",
            "0: 480x640 3 persons, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.85\n",
            "\n",
            "0: 480x640 3 persons, 7.0ms\n",
            "Speed: 2.2ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.75\n",
            "F1-Score para roles: 0.0000\n",
            "Video: /content/hockey_dataset/data/fi5_xvid.avi\n",
            "Frames con agresor: 13\n",
            "Frames con víctima: 13\n",
            "¡Listo! Video guardado en: output_fi5_xvid.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_764a68f7-2eae-4c18-8d8e-7ce4daa299ed\", \"output_fi5_xvid.mp4\", 1199751)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Procesando no1_xvid.avi...\n",
            "\n",
            "0: 480x640 2 persons, 1 skateboard, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=0.00\n",
            "\n",
            "0: 480x640 2 persons, 7.8ms\n",
            "Speed: 2.2ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.22\n",
            "\n",
            "0: 480x640 2 persons, 7.7ms\n",
            "Speed: 2.3ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.32\n",
            "\n",
            "0: 480x640 2 persons, 7.3ms\n",
            "Speed: 2.2ms preprocess, 7.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.34\n",
            "\n",
            "0: 480x640 3 persons, 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.48\n",
            "\n",
            "0: 480x640 3 persons, 7.8ms\n",
            "Speed: 2.1ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.59\n",
            "\n",
            "0: 480x640 3 persons, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.60\n",
            "\n",
            "0: 480x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.72\n",
            "\n",
            "0: 480x640 2 persons, 7.1ms\n",
            "Speed: 2.6ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.85\n",
            "\n",
            "0: 480x640 2 persons, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.93\n",
            "\n",
            "0: 480x640 2 persons, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.83\n",
            "\n",
            "0: 480x640 2 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.91\n",
            "\n",
            "0: 480x640 2 persons, 7.5ms\n",
            "Speed: 2.0ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.70\n",
            "\n",
            "0: 480x640 2 persons, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.76\n",
            "\n",
            "0: 480x640 2 persons, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.90\n",
            "\n",
            "0: 480x640 1 person, 1 baseball bat, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.05\n",
            "\n",
            "0: 480x640 1 person, 1 baseball bat, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.12\n",
            "\n",
            "0: 480x640 1 person, 1 baseball bat, 1 baseball glove, 7.8ms\n",
            "Speed: 3.1ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.12\n",
            "\n",
            "0: 480x640 1 person, 1 baseball bat, 1 baseball glove, 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.13\n",
            "\n",
            "0: 480x640 1 person, 1 baseball bat, 7.0ms\n",
            "Speed: 2.3ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.28\n",
            "\n",
            "0: 480x640 1 person, 1 train, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.44\n",
            "\n",
            "0: 480x640 1 person, 1 baseball glove, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.63\n",
            "\n",
            "0: 480x640 2 persons, 1 baseball glove, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.60\n",
            "\n",
            "0: 480x640 3 persons, 1 baseball glove, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.60\n",
            "\n",
            "0: 480x640 1 person, 2 baseball gloves, 7.4ms\n",
            "Speed: 2.3ms preprocess, 7.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.52\n",
            "\n",
            "0: 480x640 2 persons, 1 train, 1 baseball glove, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 0 (mano y=0.47, dist_x=70.27, dist_y=28.05, mag=3.50) cerca de víctima 1\n",
            "\n",
            "0: 480x640 3 persons, 1 baseball glove, 1 tennis racket, 7.5ms\n",
            "Speed: 1.9ms preprocess, 7.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.49, dist_x=68.18, dist_y=12.67, mag=3.52) cerca de víctima 0\n",
            "\n",
            "0: 480x640 2 persons, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.33\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 2 persons, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.02\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.25\n",
            "Persistiendo roles por 4 frames más\n",
            "Procesados 30 frames...\n",
            "\n",
            "0: 480x640 3 persons, 1 snowboard, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 1 (mano y=0.59, dist_x=7.92, dist_y=50.03, mag=3.14) cerca de víctima 2\n",
            "\n",
            "0: 480x640 4 persons, 1 baseball glove, 6.8ms\n",
            "Speed: 2.9ms preprocess, 6.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.19\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 4 persons, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.10\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 4 persons, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=3.03\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 3 persons, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Detectado agresor 2 (mano y=0.56, dist_x=20.30, dist_y=61.86, mag=2.89) cerca de víctima 1\n",
            "\n",
            "0: 480x640 3 persons, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.77\n",
            "Persistiendo roles por 6 frames más\n",
            "\n",
            "0: 480x640 5 persons, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=2.37\n",
            "Persistiendo roles por 5 frames más\n",
            "\n",
            "0: 480x640 3 persons, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.84\n",
            "Persistiendo roles por 4 frames más\n",
            "\n",
            "0: 480x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.58\n",
            "Persistiendo roles por 3 frames más\n",
            "\n",
            "0: 480x640 3 persons, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.26\n",
            "Persistiendo roles por 2 frames más\n",
            "\n",
            "0: 480x640 3 persons, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No se detectó: manos bajas/lejanas, mag=1.18\n",
            "Persistiendo roles por 1 frames más\n",
            "F1-Score para roles: 1.0000\n",
            "Video: /content/hockey_dataset/data/no1_xvid.avi\n",
            "Frames con agresor: 16\n",
            "Frames con víctima: 16\n",
            "¡Listo! Video guardado en: output_no1_xvid.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a3da8bbd-5d0d-44bd-8d0e-28d846f075ee\", \"output_no1_xvid.mp4\", 843694)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reporte Final:\n",
            "fi1_xvid.avi: Agresor en 21 frames, Víctima en 21 frames, Output: output_fi1_xvid.mp4\n",
            "fi2_xvid.avi: Agresor en 29 frames, Víctima en 29 frames, Output: output_fi2_xvid.mp4\n",
            "fi3_xvid.avi: Agresor en 35 frames, Víctima en 35 frames, Output: output_fi3_xvid.mp4\n",
            "fi4_xvid.avi: Agresor en 39 frames, Víctima en 39 frames, Output: output_fi4_xvid.mp4\n",
            "fi5_xvid.avi: Agresor en 13 frames, Víctima en 13 frames, Output: output_fi5_xvid.mp4\n",
            "no1_xvid.avi: Agresor en 16 frames, Víctima en 16 frames, Output: output_no1_xvid.mp4\n"
          ]
        }
      ]
    }
  ]
}