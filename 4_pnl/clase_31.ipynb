{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davidlealo/sic_ai_2025_sept/blob/main/4_pnl/clase_31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2Tl77_SjNnY"
   },
   "source": [
    "# üìò Visualizar textos en TensorFlow Projector: Paso a Paso en Google Colab\n",
    "\n",
    "Este tutorial explica c√≥mo transformar textos (por ejemplo, art√≠culos constitucionales) en vectores para ser visualizados en [https://projector.tensorflow.org](https://projector.tensorflow.org).\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Paso 1: Cargar tus textos\n",
    "\n",
    "Simulamos una lista de art√≠culos constitucionales:\n",
    "\n",
    "```python\n",
    "textos = [\n",
    "    \"Art√≠culo 1: Chile es una rep√∫blica democr√°tica, fundada en la soberan√≠a popular.\",\n",
    "    \"Art√≠culo 2: La soberan√≠a reside en el pueblo de Chile.\",\n",
    "    \"Art√≠culo 3: El Estado se organiza en tres poderes independientes.\",\n",
    "    \"Art√≠culo 4: La Constituci√≥n garantiza la igualdad ante la ley.\",\n",
    "    \"Art√≠culo 5: El medio ambiente debe ser protegido por el Estado.\",\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Paso 2: Instalar librer√≠as necesarias\n",
    "\n",
    "Usamos `sentence-transformers` para generar buenos embeddings multiling√ºes:\n",
    "\n",
    "```python\n",
    "!pip install -q sentence-transformers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Paso 3: Convertir los textos a vectores (embeddings)\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo multiling√ºe\n",
    "modelo = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# Crear los vectores\n",
    "vectores = modelo.encode(textos)\n",
    "\n",
    "# Guardamos los textos como etiquetas para visualizaci√≥n\n",
    "etiquetas = textos\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Paso 4: Guardar archivos `.tsv`\n",
    "\n",
    "```python\n",
    "# Guardar los vectores en vectors.tsv\n",
    "pd.DataFrame(vectores).to_csv(\"vectors.tsv\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Guardar los textos originales como metadatos\n",
    "pd.DataFrame(etiquetas).to_csv(\"metadata.tsv\", sep=\"\\t\", header=False, index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Paso 5: Descargar los archivos a tu computador\n",
    "\n",
    "Puedes usar el explorador de archivos lateral en Colab o ejecutar:\n",
    "\n",
    "```python\n",
    "from google.colab import files\n",
    "files.download(\"vectors.tsv\")\n",
    "files.download(\"metadata.tsv\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Paso 6: Cargar en TensorFlow Projector\n",
    "\n",
    "1. Ir a: [https://projector.tensorflow.org/](https://projector.tensorflow.org/)\n",
    "2. Hacer clic en ‚Äú**Load**‚Äù\n",
    "3. Subir:\n",
    "   - `vectors.tsv` como **Tensor**\n",
    "   - `metadata.tsv` como **Metadata**\n",
    "4. Explorar con **PCA, t-SNE o UMAP**, y buscar similitudes entre textos.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Opcional: Leer textos desde archivo `.txt` o `.csv`\n",
    "\n",
    "Si tienes los art√≠culos en un archivo `constitucion.txt` (una l√≠nea por art√≠culo), haz:\n",
    "\n",
    "```python\n",
    "# Subir archivo\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Leer textos desde el archivo\n",
    "with open(\"constitucion.txt\", encoding=\"utf-8\") as f:\n",
    "    textos = [line.strip() for line in f if line.strip()]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ ¬°Listo!\n",
    "Ahora puedes explorar tus textos en un espacio sem√°ntico con TensorFlow Projector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMNDVIwYiwOi",
    "outputId": "cb6d6c97-dadc-41d7-910a-ee8db75f16ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivos en la carpeta 'corpus':\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Crear la carpeta 'corpus' si no existe\n",
    "os.makedirs(\"corpus\", exist_ok=True)\n",
    "\n",
    "# Mover archivos PDF y EPUB cargados al entorno a la carpeta 'corpus'\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".pdf\") or file.endswith(\".epub\"):\n",
    "        print(f\"Moviendo {file} a carpeta corpus\")\n",
    "        shutil.move(file, os.path.join(\"corpus\", file))\n",
    "\n",
    "# Confirmar contenido de la carpeta\n",
    "print(\"\\nArchivos en la carpeta 'corpus':\")\n",
    "print(os.listdir(\"corpus\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "KJ3YuU8Zjuhl",
    "outputId": "815d2e69-bd3b-48ff-bb7c-8ba0d9f6e46a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-968249e6-76e6-4c9b-a937-c97284645f0d\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-968249e6-76e6-4c9b-a937-c97284645f0d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving gm_tomo2.epub to gm_tomo2.epub\n",
      "Saving tomo3_e.epub to tomo3_e.epub\n",
      "Saving tomo4_gm.epub to tomo4_gm.epub\n",
      "Saving tomo5_gm(2).epub to tomo5_gm(2).epub\n",
      "Saving tomo6_m-1.pdf to tomo6_m-1.pdf\n",
      "Saving tomo7_m.pdf to tomo7_m.pdf\n",
      "Saving tomo8_m.pdf to tomo8_m.pdf\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Subir archivos .pdf y .epub desde tu equipo\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l9WelFVLk7IU"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ebooklib PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHdvtw1Qldln",
    "outputId": "2d39c189-3a9e-4ca5-d250-849809c163c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviendo tomo6_m-1.pdf a carpeta corpus/\n",
      "Moviendo tomo5_gm(2).epub a carpeta corpus/\n",
      "Moviendo tomo4_gm.epub a carpeta corpus/\n",
      "Moviendo tomo3_e.epub a carpeta corpus/\n",
      "Moviendo tomo8_m.pdf a carpeta corpus/\n",
      "Moviendo gm_tomo1.epub a carpeta corpus/\n",
      "Moviendo gm_tomo2.epub a carpeta corpus/\n",
      "Moviendo tomo7_m.pdf a carpeta corpus/\n",
      "\n",
      "Contenido de la carpeta corpus:\n",
      "['tomo6_m-1.pdf', 'tomo5_gm(2).epub', 'tomo4_gm.epub', 'tomo3_e.epub', 'tomo8_m.pdf', 'gm_tomo1.epub', 'gm_tomo2.epub', 'tomo7_m.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Crear carpeta corpus si no existe\n",
    "os.makedirs(\"corpus\", exist_ok=True)\n",
    "\n",
    "# Mover todos los archivos .pdf y .epub que est√©n en la ra√≠z a la carpeta corpus\n",
    "for archivo in os.listdir():\n",
    "    if archivo.endswith(\".pdf\") or archivo.endswith(\".epub\"):\n",
    "        if not archivo.startswith(\"corpus\"):  # Evitar mover de nuevo si ya est√°n ah√≠\n",
    "            print(f\"Moviendo {archivo} a carpeta corpus/\")\n",
    "            shutil.move(archivo, os.path.join(\"corpus\", archivo))\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(\"\\nContenido de la carpeta corpus:\")\n",
    "print(os.listdir(\"corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_cyBpqglxgS",
    "outputId": "6bd5b82e-4bac-467b-d82b-08f0142ec55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo PDF: tomo6_m-1.pdf\n",
      "Extrayendo EPUB: tomo5_gm(2).epub\n",
      "Extrayendo EPUB: tomo4_gm.epub\n",
      "Extrayendo EPUB: tomo3_e.epub\n",
      "Extrayendo PDF: tomo8_m.pdf\n",
      "Extrayendo EPUB: gm_tomo1.epub\n",
      "Extrayendo EPUB: gm_tomo2.epub\n",
      "Extrayendo PDF: tomo7_m.pdf\n",
      "\n",
      "Longitud total del corpus: 4647275 caracteres\n"
     ]
    }
   ],
   "source": [
    "# 1. Librer√≠as necesarias\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from ebooklib import epub, ITEM_DOCUMENT\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_epub_text(path):\n",
    "    book = epub.read_epub(path)\n",
    "    text = ''\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ITEM_DOCUMENT:\n",
    "            soup = BeautifulSoup(item.get_content(), 'html.parser')\n",
    "            text += soup.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# 3. Funci√≥n para PDF\n",
    "def extract_pdf_text(path):\n",
    "    text = ''\n",
    "    with fitz.open(path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# 4. Extraer textos\n",
    "corpus_path = \"corpus\"\n",
    "textos_completos = \"\"\n",
    "\n",
    "for archivo in os.listdir(corpus_path):\n",
    "    ruta = os.path.join(corpus_path, archivo)\n",
    "    if archivo.endswith(\".epub\"):\n",
    "        print(f\"Extrayendo EPUB: {archivo}\")\n",
    "        textos_completos += extract_epub_text(ruta) + \"\\n\"\n",
    "    elif archivo.endswith(\".pdf\"):\n",
    "        print(f\"Extrayendo PDF: {archivo}\")\n",
    "        textos_completos += extract_pdf_text(ruta) + \"\\n\"\n",
    "\n",
    "print(\"\\nLongitud total del corpus:\", len(textos_completos), \"caracteres\")\n",
    "\n",
    "# 5. Guardar en archivo\n",
    "with open(\"gabriela_mistral_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textos_completos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFVZVKdAmKk-",
    "outputId": "da4227b5-1d19-4652-d386-780d90005d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de tokens: 840658\n"
     ]
    }
   ],
   "source": [
    "# Cargar corpus\n",
    "with open(\"gabriela_mistral_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "# Limpiar y tokenizar\n",
    "import re\n",
    "tokens = re.findall(r'\\b\\w+\\b', corpus.lower())  # palabras min√∫sculas sin signos\n",
    "print(f\"N√∫mero de tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DfK_mr9ImOyn"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cs5IhorLmXRk"
   },
   "outputs": [],
   "source": [
    "# Supongamos que etiquetas es un solo string largo\n",
    "with open(\"gabriela_mistral_corpus.txt\", encoding=\"utf-8\") as f:\n",
    "    texto_largo = f.read()\n",
    "\n",
    "# O si ya lo tienes cargado:\n",
    "# texto_largo = etiquetas\n",
    "\n",
    "# Dividir por l√≠neas con contenido\n",
    "etiquetas = [line.strip() for line in texto_largo.splitlines() if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560,
     "referenced_widgets": [
      "f9c924a21dd44084b2618cc5d91aafb9",
      "94951c9c310848ec94bcb6a7742c2b1f",
      "978ed03be0434d2695e45a84d46bea91",
      "7e2e384d1b3f4e13acbba3c5432b42ba",
      "afe83133a9194eb3ac87479c164f682e",
      "131540fa33b144e2a5ab40e994f1d590",
      "79592fe3a3fa456786cdcf7562cb1a60",
      "813a9d5faf714d878adbc46fe8286195",
      "a2d4a6dab16e49538553a12a3fc4a095",
      "3b04d469385d4dc09e61d14592f90166",
      "142d594b89ea48b58196f82e44f665d8",
      "7e5d11707b3440128d837408152e4835",
      "f018f6873ef44a51921dde1727b2a1d5",
      "82934d883b16412c90d8b51127b8d079",
      "abd3614cc5b14b8e9dfa49159c06abd1",
      "28401de4dd5d448eaf10d67aa8f50eda",
      "7874f17d9bba434aaa6a950b39e093b3",
      "420fc5fe01154263812634dce34d7e71",
      "742e070e8c9d4590a25a9057c297b440",
      "a62c7925548648aa97264b32a129498f",
      "f2a7878b9e874f1ca60480b0bcd8aa38",
      "c1810907fb60441a9f6217b5ea36d6f5",
      "4d60f83fbdb7451c9ac0b338601e450e",
      "6afb5302b9e742329796f300631b5b8f",
      "2476c08c58ab4b3aab5c30a9fbf69562",
      "0ef998f8333243e486aff5f9f9147f30",
      "ad21cff68142480ca4d9a5a8c43a8ebd",
      "0b271d2a7189425caffa52bc87c7fb16",
      "5b737dea69214222a3dca1d76d7a6e83",
      "b2ba77705fc643409629f2d0062840fd",
      "af016fc36ec7400384513a3074a2b091",
      "0b9fc9883c85459a8cbdb3846aebeb46",
      "d9ebe9e515ce44449b030b0cda30ab49",
      "f7cd63980b6243cb8eeeca2fb8dcd6ee",
      "504b38797b3e4a54a3ece1f1918afe45",
      "2f780d8c3ed34859bf12251696319bf4",
      "49327c2bc1d74c578e594f455a66547b",
      "3d9bfce9c708461bb29d402888b801f6",
      "afb201cd63e0428c82946832282c9d3a",
      "4167c23dfe554a8abbcea1be57686cfc",
      "7d408b8bb11b4a6fb76247d40cd1729f",
      "f0e945318e7c4e24825e0f26f682c0c3",
      "a0c912793ef94122b9d24ad4cc6c4a64",
      "016af3cd69f54d64a5ed52ccac13dbb6",
      "af3b117565da43f2a497ebd6074cc2cb",
      "5ed07ecaa7614ccfb0815942a901ea41",
      "94163a8720934db3b4b126ef2fe7e20e",
      "2904faa4535f4fca9067856bb400ae4c",
      "6bcd488e6ee0495aaa4d782afede8ee2",
      "b22a90a55c73405fb503907605177255",
      "23d56bb59e4e4be99edc2adc02ae9b01",
      "4702d73d69f74902a75e718e14b8f20d",
      "ecc32b40ee974287930fdd37ea578b9a",
      "1b24fe183af943b4a982d3f1d774a183",
      "258277c38ca9495a95e62c03eb3cd55c",
      "250f49aa16ff47a5b974e350c8b77120",
      "1531d80313634c4f985e446111f64aed",
      "c59295142a2e4d9bb368ff4a6e8d3923",
      "1dd03a574b7a4a8d8b9309403300060a",
      "a1284058d2424581a05e6c909a6649ea",
      "43322a893ad540df846b506d1e94a2bd",
      "eb25eb512ce645f8b78c7a4b906d9da3",
      "7bc2a90b5db74e1bad57f9f8f5266995",
      "c8054740c65a491ba45bc7b6122ae901",
      "998588c3ca1c4a8d99e48f7ac0217773",
      "dce3faefe3d141b58106ef64d798cc32",
      "b16c523728fb4083a60a456a32bffd80",
      "d0d005b379734050ba6db310a1d122e5",
      "df9072342f9f4166b07345c9efd2991c",
      "e2e4ecb214f843bfb2f3b6257152d49e",
      "0478180b73304696915e0df37f6fb74a",
      "baa66ac9f32a4252a33fa866b63366c0",
      "e0d7ff824d344ce4a355af9df72d42ac",
      "6b93312023ca441ca01b7c6050adc812",
      "953e8f1961134ecc91c9b0b4eda0e42c",
      "acd49aae1bb54a039fe549c73e87fa7d",
      "a90b5bda5d6e4055b77e48cde7b6dbf3",
      "80a11991a4ad4d7aa1f67ff3fced765c",
      "cd53e1d08f8144e78ed47a243bffab2e",
      "0ffc362431074e149ba10db7299e698e",
      "08cd0d885f90463896316a296c0b36ec",
      "bea5a91921d14c4d92c5a3ca31a7f3b2",
      "9da740cf367f4863947c2e0d83b8596b",
      "9940db2d474c44008fde0db588c63075",
      "ff9dc45e9512428799b9e7a945ab4a48",
      "d5d85ef19c0640bfad01863e9e81ba59",
      "2a08b974cfe8446c8c9520cbb3fb1160",
      "f4d70545fb534a7d99deffae14c64989",
      "1a0ab6b4d13a4c86bf3395a2843b08df",
      "437e296d4e0f4b48a315f0a88b07ee68",
      "208190de7f2a4c60b29d57ab2194b1be",
      "9845e40546f6409483cfb9482b509d55",
      "0c0e9a722711426189df8d2e233a1ac2",
      "3bf8a15fc6014d5b9074de52f52b706e",
      "467d9cc8c50b45b6b7f6c24faf15953e",
      "1db38960903d45aa9e37ee50e8120c11",
      "a149b7786ee84256b23c96c39f873255",
      "e06f24c1e9e744e995d514f75732a067",
      "5b45a8a3e7c744138f1736d85e4aeea9",
      "88c1c3c01c374075b46127a75a1dc4a6",
      "d90ec6f5f23145acb344f9b3536842ec",
      "a6393381b1984e40a916613640a081be",
      "c9c61ccbb77f4fb7a043f90be6737d0b",
      "b3f66922662f4bb3b7515aad736eaa1c",
      "04759e36e1bd4fe2b763df3e8d421754",
      "0fbeff89aede43e7b7ee084ffb7d33ae",
      "7a16091a4c3146f48f0a0b530ca38d6c",
      "8ebd25c977b740e1b0fd17c8d9879b1e",
      "a8e4111ca6f14151838c67ccdf90ebd8",
      "1bcbd8621903444e8c08ffa5a3dfa395",
      "f1cf806a0caa43f48330ae0fd286ff27",
      "bec602859a264a61860fe43f57951322",
      "c1e7b48bff4d49fdbbe048554d45e982",
      "19eb9598ec3c4b7991e83e9a143fa1fa",
      "7e2b55712a2f4b28bc0f842304fbaea4",
      "5e2930761239434cb61e1b1b50e1839c",
      "af3e9f50a9a44c109f14abd9fbe58e96",
      "6328f2a7cf6746ce85a86cbe7058144c",
      "103988afedcc426bb7cc6191c497942d",
      "c422266ba00944d19b105d1850d75b8a",
      "7d70aabb425841f991b261f10a383f90",
      "b4b2aa8b41ff4989858d0e4958ea2e60",
      "dad012957caa4c2f9927b4a3af0af0dd",
      "d4831527fd1743e3945958f28233fac8",
      "3a74fd85d6d443ee80af193a9e962b64",
      "4888e3f2e1ad4bb9bf0755264e145bb2",
      "43d11d88cc8f4401aa492e81972d7be3",
      "c48966ba347141f49c7d46501ef5b52f",
      "7ef3bc8fce714d4694a66d91514c7ac8",
      "5b5051c9f7524c2380375e66675c0f7d",
      "ee64df33bfa94d6d984b88fd988b18b8",
      "b95ff9feef754edcb15eb964c077b4b1",
      "0fd7e6885a8a40dd867b2600b3315bdf",
      "d89557c253154231a145fd64da792735",
      "2ae93303f37d421d85b3544a68263f0b",
      "d45523ea1a93427a8d89fa00214d5226",
      "79a870cf6f4440488163a96d004a32a0",
      "55bb54ca6eb9451b8a8d5904dba2bc45",
      "0e56d4a9fa1d49eb9186222a73bc7ee8",
      "aab767c97514461abd63e52dc7cf58d2",
      "df366b93667c41edba9cfe92b621ae97",
      "d8d2375e5824472f8ccc9ff0cee1e955",
      "3a45fc2d52f74583b70ce7b00806b7f7"
     ]
    },
    "id": "-BDijTqpmZ9N",
    "outputId": "0b3a6ab3-276d-4cca-9b24-9cde08ad9d12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c924a21dd44084b2618cc5d91aafb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5d11707b3440128d837408152e4835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d60f83fbdb7451c9ac0b338601e450e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cd63980b6243cb8eeeca2fb8dcd6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3b117565da43f2a497ebd6074cc2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250f49aa16ff47a5b974e350c8b77120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16c523728fb4083a60a456a32bffd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a11991a4ad4d7aa1f67ff3fced765c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0ab6b4d13a4c86bf3395a2843b08df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c1c3c01c374075b46127a75a1dc4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cf806a0caa43f48330ae0fd286ff27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b2aa8b41ff4989858d0e4958ea2e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd7e6885a8a40dd867b2600b3315bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo multiling√ºe\n",
    "modelo = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# Crear los vectores\n",
    "vectores = modelo.encode(corpus)\n",
    "\n",
    "# Guardamos los textos como etiquetas para visualizaci√≥n\n",
    "etiquetas = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yromdGaTm-2E",
    "outputId": "104c8c89-e959-440d-c608-afc948a4d98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4647275\n",
      "S E L\n"
     ]
    }
   ],
   "source": [
    "print(len(etiquetas))\n",
    "print(etiquetas[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "14b521fa7e10488b9dc36db1dbc023b6",
      "2bf7d5bf7fae40a2a984bb0b5e0fc53f",
      "98382cc70633436bb3af7ab9cc2de232",
      "1ce4375c500c4514ad53e343d092b243",
      "ad4fc736e9a54dc5bd456bab27ac9e59",
      "97c8248463f24ccaa80148018459294c",
      "e600c658a01f4a1884822bcf2bb166bb",
      "9d4e683cdfc24fcd9bfa4a06df39c582",
      "2d72779635a845d698ac879365b1450e",
      "bba3b90814fd41a193c2dab6f7db340d",
      "3d408ab424f04cf3b35546f9437f9bae",
      "c6533a2cbdd5474a856778b24f8f0ca8",
      "cb1a56d94d064ba3a6fcffda1b51b1a8",
      "645d808d96c649308d833986838dc617",
      "9efb964ab2024b0f9a1003ebdab66fe6",
      "755fade1224244fb9c1fac00dc60c3b9",
      "e67379401f1d4d518fdcc90f47fbf320",
      "531bca8cb9b341b98a607b6ab99c5d64",
      "a1eac585bfd64ce7b51e714999a78f04",
      "f0cd7f676282408d94651200cdf041b5",
      "cf0e47373da549419faf9c831c89c44b",
      "f3d543f352cc421c9256c0d067dc11d7",
      "f730d6233d77471ea1febce52677bfc5",
      "50ab1a2fdf72446ba0962839e7ee5f00",
      "ed468ab15cf5441cbd5108dbdb152a82",
      "0e0fbc5a023d443583702295c384a0cf",
      "903953114278421c8cb1869b6e8be281",
      "beb88ca35f9b4014bdbef8e4b501e2f3",
      "100ca97c65744b04951885b6d8f69326",
      "ab33aa51a690466bbc8f4e27fe3f26be",
      "8c391a69d6cf41948a68f4fe3cb989e5",
      "d9d437014b7b4ffd84ece29d0c554927",
      "d6a0db8102fa476a871cd8a4b309c259",
      "9e6a28badf51424aad6b4e258fd98b69",
      "113d0d775c60405ba1ba70de112b987a",
      "2ed38227b1eb416ea8437b40d4e1141e",
      "d1128455796b44d18a781282f4918bdf",
      "03409a336de74d6692eb9f315dba8630",
      "cc5a0914505140aca0fe5ff85fc03098",
      "94332b53992a4267a59eab96a4efe570",
      "84fc0944aba3446298b829f41ed0a66c",
      "3c06f14208e24320ae39dd36bc9591fd",
      "cd6ca79bf7494193b2e84094048de34f",
      "4c88b7dd6bcd484b9f38eb77fbab3397",
      "439ea9dd3fc742248141dc992eaa80c8",
      "6e82a23524a44068a1bf6e751f46b95a",
      "0fdd7d5e360f4537ae98d58ec4cad6b6",
      "51f49146fd73431f847159a119e40abb",
      "051e8d1f07b24f699b3f1d04d767f18d",
      "33fd5e3e0163456e946f648a1b7bf542",
      "0c9e6c2a3f83492db79fb7563d76ed19",
      "116fc8fb1b794dc4a3f8092d942cc78d",
      "43747ff2f34c4030900a2bf94ca80a18",
      "366f479b580546a381d4044331a20e0d",
      "a933af1b8a2d45e8b98b7a4fe0fb0e3e",
      "5f0c1cdb9cbc4f188766f05043380b10",
      "18f956e1747447c69750c3415db9c327",
      "a1f6d53acb734519a82843c9f00f1ed2",
      "a6f7721cfc8c4641badd0f1edca466cb",
      "a083f28c90c6415ca957871231afbae1",
      "b236ec528cf14b01bc409cc7a04a2c5c",
      "853c8a2776e1429c921b663f4bf12366",
      "d4a9abe961c6443fb75a943c5a602f18",
      "31d4385fe3974762886a0103307f17b2",
      "d6bec2b7ae84487f93250b63178d271a",
      "31c25abb81774ece8356544a620e76fc",
      "91fd054bcdf14665b242f60e3900eb5c",
      "ab0f1cf7af8e4df6a452d427b18589ac",
      "ee3098a8036b45af8f355ead60093bca",
      "1eb39b5a6d5f401998980e8edf78cefb",
      "be3294e5ca1a4d9bac3aaa8d54fe27be",
      "9b1ac3bfe2624a49914e089d67bbd753",
      "9a32b3c94d434e49ac8588d4cdff460d",
      "1d41e83c0176478e841c6e0adc536a06",
      "71ae99d83fe445bb8cddb4e9052c9cc6",
      "164b1e2918284bb79bea400c63123346",
      "8d36658783e140768ecbbb55bce2f1dc",
      "e153b26733de49bc8a6fcde33f30954f",
      "7f304aa4134a447dbab9e44ac5533ac9",
      "ae51edb0a05e4e0b9eaa4a312058cc72",
      "10535c74c43b4bc4a4ceaa3952518c67",
      "75a97f37d1cf4cfdad388f43299d9aa8",
      "4277ee47c07a49a9842d8ed04e664464",
      "96180e3dd8cf4ec5985a8713d1a40c2e",
      "10ae4272693c40fdbd051985185c7795",
      "1006e8f80a0843c286ddca70af221b14",
      "a65fc9f7ef5e4e6f81d9e8228455d01d",
      "e9a74a0476f14cf0be91ab6128589ec5",
      "07675e4ba1cd49efbe08265d69992a00",
      "3a8fadcbd1634231a9d82cda0dfd7362",
      "d7a46424889a43d0b5002d0002c204ad",
      "c91eeddc8f094bbeac48f8243701f039",
      "702126914d1343f5a1ee640e91008584",
      "af474e27c0144990b06f0d7f40e2dd27",
      "4d2618052c2b407484230ecaa04fad74",
      "e22aec761fbd4be98b331c0fdf5a6077",
      "0ade3fa61076424e9fd549029407dc73",
      "8823e4a8faa44a509c04cc4d852094e8",
      "9cd6a879565a49b981291e6d0ba833de",
      "a50e1d375605438b94e4dd5926d4e25f",
      "e0a5b72d2a4d42979dd5532c5436ee80",
      "0ec50b5950ba47beb3dfbbd64f3f12f8",
      "42459d4cc7944d7491c8ea0d0cb0ad1a",
      "0a7d24bba4494ae0871d9133b89d6fb2",
      "6dba9d97d8b742c19a9f6ab9a87f108c",
      "f3f4a5c9894a4349b68e36a6a15625a4",
      "f6be8ccd8531479fbcd4cfa276592471",
      "65e6b02935154e75b4049367cd88aa64",
      "c2949021169a42cdb881057885381487",
      "e10f79bda5bf441d9729ee4132f423da",
      "0b3f40ef9aaa4077975ad75e42f40ec4",
      "776b0bd0b1444aceab49133c412704f9",
      "f9ed3b33aae041489ff7a5589636dce1",
      "65ed4178c1184276b60fb787324f0124",
      "336e96af1f7646f9b0b6605db3bf8cc2",
      "07d17b85d3eb42e2b3730c9c490081bd",
      "8df80f58a0f246fab8d3a6c0c071d52e",
      "333bbf7f1a074a5e9f9f662a06eb2ff7",
      "151078b300ac4af893447b2641077fed",
      "bf53c822ec914709bfcf2b216a135e7e",
      "2484fa7643e24eceb81135911dbb24ab"
     ]
    },
    "id": "bzCfz1vlnCbd",
    "outputId": "4e13e662-9f36-4cf4-a04a-f6e89dc30a65"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b521fa7e10488b9dc36db1dbc023b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6533a2cbdd5474a856778b24f8f0ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f730d6233d77471ea1febce52677bfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6a28badf51424aad6b4e258fd98b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439ea9dd3fc742248141dc992eaa80c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0c1cdb9cbc4f188766f05043380b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fd054bcdf14665b242f60e3900eb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e153b26733de49bc8a6fcde33f30954f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07675e4ba1cd49efbe08265d69992a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50e1d375605438b94e4dd5926d4e25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3f40ef9aaa4077975ad75e42f40ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el texto\n",
    "with open(\"gabriela_mistral_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    frases = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Generar embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "vectors = model.encode(frases)\n",
    "\n",
    "# Guardar archivos para TensorFlow Projector\n",
    "pd.DataFrame(vectors).to_csv(\"vectors.tsv\", sep=\"\\t\", header=False, index=False)\n",
    "pd.DataFrame({'text': frases}).to_csv(\"metadata.tsv\", sep=\"\\t\", header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "xvjMGtzVwBn9",
    "outputId": "5c019e2f-8f40-4c55-f20b-288370c6caeb"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_4b92f0af-0015-4d28-93f5-fcf2e41fb78c\", \"vectors.tsv\", 531664492)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_42475feb-d3fe-4ad5-aff9-aa6eb099a605\", \"metadata.tsv\", 4669664)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"vectors.tsv\")\n",
    "files.download(\"metadata.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "4sRet5RCzn5L",
    "outputId": "80b9a944-27fa-4f1d-bb7b-38820c7696f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras √∫nicas: 51322\n",
      "Listo. Archivos 'vectors.tsv' y 'metadata.tsv' generados correctamente.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_d42c259e-3743-4c77-b7d6-4f98d51a9413\", \"vectors.tsv\", 241091818)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_669ce6cb-ccbd-4890-9c18-7b095c01334f\", \"metadata.tsv\", 470140)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Importar librer√≠as necesarias\n",
    "# ============================================================\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ============================================================\n",
    "# 2. Cargar el corpus de Gabriela Mistral\n",
    "# ============================================================\n",
    "with open(\"gabriela_mistral_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texto = f.read()\n",
    "\n",
    "# ============================================================\n",
    "# 3. Preprocesamiento del texto\n",
    "#    - Eliminar n√∫meros\n",
    "#    - Eliminar caracteres no alfab√©ticos\n",
    "#    - Convertir a min√∫sculas\n",
    "# ============================================================\n",
    "texto = re.sub(r\"\\d+\", \"\", texto)                # eliminar n√∫meros\n",
    "texto = re.sub(r\"[^A-Za-z√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±√º√ú\\s]\", \"\", texto)  # eliminar signos\n",
    "texto = texto.lower()                            # pasar a min√∫sculas\n",
    "\n",
    "# ============================================================\n",
    "# 4. Tokenizaci√≥n por palabra (no por frase)\n",
    "# ============================================================\n",
    "# Dividir en palabras (puedes cambiarlo por split() o usar nltk.word_tokenize)\n",
    "palabras = texto.split()\n",
    "# Remover duplicados opcionalmente\n",
    "palabras_unicas = list(set(palabras))\n",
    "\n",
    "print(f\"Total de palabras √∫nicas: {len(palabras_unicas)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Generar embeddings por palabra\n",
    "# ============================================================\n",
    "modelo = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "vectores = modelo.encode(palabras_unicas)\n",
    "\n",
    "# ============================================================\n",
    "# 6. Guardar archivos para TensorFlow Projector\n",
    "# ============================================================\n",
    "# Cada fila del TSV de vectores corresponde a una palabra\n",
    "pd.DataFrame(vectores).to_csv(\"vectors.tsv\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# El archivo de metadata contiene las etiquetas (las palabras)\n",
    "pd.DataFrame({'word': palabras_unicas}).to_csv(\"metadata.tsv\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "print(\"Listo. Archivos 'vectors.tsv' y 'metadata.tsv' generados correctamente.\")\n",
    "\n",
    "files.download(\"vectors.tsv\")\n",
    "files.download(\"metadata.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlpArK01AKhB"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/mauridb/product-data-from-walmart-usa-with-embeddings?utm_source=chatgpt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ht0-A8NNBlmK"
   },
   "source": [
    "### **1. Instalaci√≥n e importaci√≥n de librer√≠as**\n",
    "\n",
    "```python\n",
    "!pip install sentence-transformers faiss-cpu gradio kagglehub -q\n",
    "```\n",
    "\n",
    "Instala las librer√≠as necesarias:\n",
    "\n",
    "* **sentence-transformers:** genera representaciones vectoriales (embeddings) de texto.\n",
    "* **faiss-cpu:** permite crear un √≠ndice para realizar b√∫squedas vectoriales eficientes.\n",
    "* **gradio:** crea una interfaz web interactiva para el usuario.\n",
    "* **kagglehub:** descarga datasets directamente desde Kaggle.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import gradio as gr\n",
    "import os\n",
    "```\n",
    "\n",
    "Importa las librer√≠as ya instaladas:\n",
    "\n",
    "* `pandas` para manejo de datos tabulares.\n",
    "* `numpy` para operaciones num√©ricas.\n",
    "* `SentenceTransformer` para crear embeddings.\n",
    "* `faiss` para la b√∫squeda vectorial.\n",
    "* `gradio` para crear la interfaz.\n",
    "* `os` para trabajar con rutas de archivos.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Cargar dataset desde KaggleHub**\n",
    "\n",
    "```python\n",
    "import kagglehub\n",
    "```\n",
    "\n",
    "Importa el m√≥dulo `kagglehub` para conectar con Kaggle.\n",
    "\n",
    "```python\n",
    "path = kagglehub.dataset_download(\"mauridb/product-data-from-walmart-usa-with-embeddings\")\n",
    "print(\"Ruta de los archivos del dataset:\", path)\n",
    "```\n",
    "\n",
    "Descarga el dataset **‚Äúproduct-data-from-walmart-usa-with-embeddings‚Äù** desde Kaggle y guarda su ruta local. Luego la muestra por pantalla.\n",
    "\n",
    "```python\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
    "print(\"Archivos encontrados:\", csv_files)\n",
    "```\n",
    "\n",
    "Busca dentro de la carpeta descargada todos los archivos con extensi√≥n `.csv`.\n",
    "El resultado se imprime en consola para confirmar cu√°l archivo se usar√°.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(os.path.join(path, csv_files[0]))\n",
    "print(\"Columnas disponibles:\", df.columns.tolist())\n",
    "```\n",
    "\n",
    "Carga el primer archivo CSV encontrado en un DataFrame de pandas (`df`).\n",
    "Luego imprime la lista de columnas del dataset para inspecci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Limpieza y selecci√≥n de campos**\n",
    "\n",
    "```python\n",
    "df[\"text\"] = (\n",
    "    df[\"product_name\"].fillna(\"\") + \". \" +\n",
    "    df[\"description\"].fillna(\"\") + \". \" +\n",
    "    df[\"category\"].fillna(\"\") + \". \" +\n",
    "    df[\"brand\"].fillna(\"\")\n",
    ")\n",
    "```\n",
    "\n",
    "Crea una nueva columna llamada `text` combinando informaci√≥n relevante:\n",
    "\n",
    "* nombre del producto,\n",
    "* descripci√≥n,\n",
    "* categor√≠a,\n",
    "* marca.\n",
    "\n",
    "Cada campo se une en una sola cadena, separada por puntos, y se reemplazan valores nulos con cadenas vac√≠as.\n",
    "\n",
    "```python\n",
    "df = df[df[\"text\"].str.strip() != \"\"]\n",
    "```\n",
    "\n",
    "Elimina filas cuyo texto combinado est√© vac√≠o o solo tenga espacios.\n",
    "\n",
    "```python\n",
    "df[[\"product_name\", \"category\", \"brand\", \"text\"]].head(2)\n",
    "```\n",
    "\n",
    "Muestra las primeras dos filas con las columnas m√°s importantes para verificar que la combinaci√≥n se realiz√≥ correctamente.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Generar embeddings sem√°nticos**\n",
    "\n",
    "```python\n",
    "modelo = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "```\n",
    "\n",
    "Carga un modelo multiling√ºe preentrenado de **Sentence Transformers**, capaz de transformar texto en vectores num√©ricos que capturan su significado sem√°ntico.\n",
    "\n",
    "```python\n",
    "embeddings = modelo.encode(df[\"text\"].tolist(), show_progress_bar=True)\n",
    "```\n",
    "\n",
    "Convierte la columna `text` en una lista y genera un embedding para cada producto.\n",
    "El par√°metro `show_progress_bar=True` muestra una barra de progreso durante el proceso.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Crear √≠ndice FAISS**\n",
    "\n",
    "```python\n",
    "dimension = embeddings.shape[1]\n",
    "```\n",
    "\n",
    "Obtiene la dimensi√≥n de los vectores generados (por ejemplo, 768).\n",
    "\n",
    "```python\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "```\n",
    "\n",
    "Crea un √≠ndice **FAISS** basado en la distancia euclidiana (L2). Este √≠ndice permitir√° buscar los productos m√°s similares a una consulta dada.\n",
    "\n",
    "```python\n",
    "index.add(np.array(embeddings, dtype=np.float32))\n",
    "```\n",
    "\n",
    "Agrega todos los embeddings al √≠ndice, convirti√©ndolos a tipo `float32` (formato requerido por FAISS).\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Funci√≥n de b√∫squeda**\n",
    "\n",
    "```python\n",
    "def buscar(query, k=5):\n",
    "    query_vec = modelo.encode([query])\n",
    "```\n",
    "\n",
    "Define una funci√≥n llamada `buscar`.\n",
    "Primero convierte el texto de consulta (`query`) en su vector correspondiente.\n",
    "\n",
    "```python\n",
    "    D, I = index.search(np.array(query_vec, dtype=np.float32), k)\n",
    "```\n",
    "\n",
    "Realiza la b√∫squeda en el √≠ndice FAISS, retornando:\n",
    "\n",
    "* `D`: las distancias (menor = m√°s parecido).\n",
    "* `I`: los √≠ndices de los productos m√°s cercanos.\n",
    "  Busca los `k` productos m√°s similares (por defecto 5).\n",
    "\n",
    "```python\n",
    "    resultados = df.iloc[I[0]][[\"product_name\", \"category\", \"brand\", \"description\"]]\n",
    "    resultados[\"distancia\"] = D[0]\n",
    "    return resultados\n",
    "```\n",
    "\n",
    "Selecciona del DataFrame los productos correspondientes a los √≠ndices encontrados y agrega su distancia de similitud.\n",
    "Devuelve una tabla con los resultados m√°s relevantes.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Interfaz interactiva con Gradio**\n",
    "\n",
    "```python\n",
    "def interfaz(query):\n",
    "    resultados = buscar(query, k=5)\n",
    "```\n",
    "\n",
    "Crea una segunda funci√≥n que servir√° de interfaz.\n",
    "Cada vez que el usuario escriba una consulta, se llama a la funci√≥n `buscar`.\n",
    "\n",
    "```python\n",
    "    texto = \"\"\n",
    "    for _, fila in resultados.iterrows():\n",
    "        texto += f\"### {fila['product_name']} ({fila['category']})\\n\"\n",
    "        texto += f\"Marca: {fila['brand']}\\n\"\n",
    "        texto += f\"Distancia: {fila['distancia']:.4f}\\n\\n\"\n",
    "        texto += f\"{fila['description']}\\n\\n---\\n\"\n",
    "    return texto\n",
    "```\n",
    "\n",
    "Construye un texto en formato Markdown para mostrar en pantalla:\n",
    "\n",
    "* el nombre del producto y su categor√≠a,\n",
    "* la marca,\n",
    "* la distancia (nivel de similitud),\n",
    "* la descripci√≥n.\n",
    "\n",
    "El separador `---` se usa para dividir visualmente los resultados.\n",
    "\n",
    "```python\n",
    "demo = gr.Interface(\n",
    "    fn=interfaz,\n",
    "    inputs=gr.Textbox(label=\"Consulta de producto\", placeholder=\"Ejemplo: snack saludable sin az√∫car\"),\n",
    "    outputs=\"markdown\",\n",
    "    title=\"Buscador Sem√°ntico Walmart\",\n",
    "    description=\"Busca productos de Walmart por significado, combinando nombre, descripci√≥n, categor√≠a y marca.\"\n",
    ")\n",
    "```\n",
    "\n",
    "Crea la interfaz de **Gradio**:\n",
    "\n",
    "* `fn=interfaz`: funci√≥n que se ejecuta al enviar la consulta.\n",
    "* `inputs`: una caja de texto donde el usuario escribe la b√∫squeda.\n",
    "* `outputs`: muestra los resultados formateados en Markdown.\n",
    "* `title` y `description`: definen el encabezado y la descripci√≥n visibles en la interfaz.\n",
    "\n",
    "```python\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "Ejecuta la aplicaci√≥n localmente o en Google Colab.\n",
    "Abre una URL donde el usuario puede probar el buscador escribiendo cualquier descripci√≥n de producto y recibiendo resultados sem√°nticamente similares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492,
     "referenced_widgets": [
      "597c7946413d48d2805bb2a0a492fffc",
      "29407941336d4048a5a78657719bcd80",
      "e20b95c26b1d45cb9c84cd25a3b76f68",
      "9b303ff399844ab78e506995c43c7968",
      "70f9ed4880dd4ed2a15fe4b810b0c613",
      "453695addf4c4461a0afde2c8c64218c",
      "b7b9d6d86b6b4ee5b9e9e2839dd3a6d6",
      "4d06a1a9de0449cb8fc9b703b4cebbe6",
      "b7ffef9213d84d4da50f9cd61354ebc5",
      "30ca3866159a417689907d3dc2d110bf",
      "a7ee88bd2aa84e4d8b859628cc1fcad7",
      "aa06a9a04c6c4134b3cb8f19c6e92d00",
      "1f080621e66349a8aafed768a4904e8f",
      "750d6a35fef745598a4107f0e6600f09",
      "131fa4cedfa34f95ac52d336311861e5",
      "039f146261554ddbbcda7b607fa7fa05",
      "3cb31f0acdc3480bbeb5b09874c90ca0",
      "c3fa9f02063b465bb7f52cb53810c250",
      "b135d8c7d75b435eae3f57f37d6d2f25",
      "bc46fa6c90e548e498db1d71687808d8",
      "e640fdc011f341d19ce569edb2cac55d",
      "acaeb45cd2f14ba7953e4b36ffd58538",
      "a32f0448f1fd427cb6a4f5868dba17cd",
      "cbd32f7dce684e69a6558f08463db680",
      "646ef9b645b5432a83bd0d54b273f29a",
      "a6cf3cf586444278ad156b54e61f5cbf",
      "93eb0ce514d04d109e6d26260c69b1b5",
      "6d3362486caa4f80a75c33b2c61b729f",
      "00640f25cef840bbb04ec00b0566f239",
      "63f491809d27438ebf55831fcce46a75",
      "f961b7ce25ba4e55a09a3ef5f8ae7056",
      "4f6c53a048f14d9a80f0993d7f33bac3",
      "20f3d1ea122f4fdf97f3a023e7680e4c",
      "c541243226ca43f8893d225eb09e648e",
      "e1886423a3ab4e38aff2b144992fce95",
      "7df30bed743a4e3ca7717c35e1739a3e",
      "ea0e902da3034d3f8578a750fd8edd88",
      "1db8dcafb8d942a9aa97d2b444a8d924",
      "f085a4a485e6407f9316d01333bdc0d5",
      "29b55b204a764dcf99ff17fcea51f151",
      "d7281663a165492bbe83cca4ff681ce0",
      "8fc35390176c4d4d9ca4211bd81e7ca1",
      "b24af0873e4e412f9f51a25030b3c370",
      "6bd94df1b19447bfbd9cfa7a3af44c47",
      "cacaa6af60c64f4b9d342fb1ed444a58",
      "02c8207584eb40a4993c48525cc90297",
      "f78dfcf1d6de477aa405518387faa226",
      "1474e0fe3bde4b9ba3e23b134ee24318",
      "d5fc1ce84aaf4763b5da277c3a829f5f",
      "30c89e058f3e415096f4d68352e93c84",
      "a7fb0aad5c42485384f2de7ebe1c5953",
      "fc189bc1673c400fb5035ec405f6dbb1",
      "be3a1af9c09d44159cc39229f03e15dd",
      "44943d5dea83460c83e1a2677658ce86",
      "36f7e287cfc048d9b3988c1671933382",
      "f8c6afe17ec3473d818f201fa16d5cce",
      "8ad232feebbd4f1b975d5cce84bd57c0",
      "dd62da26613a42e68bdfee2d515d7f0e",
      "bc653f6cc5464bafbb0904f20ba7fe42",
      "9688f95c04f046f491bb0a10fac5ba26",
      "7884e2c9225248458bf8334d51b0310e",
      "01476144542742cf8ba21777d3fde4a6",
      "32901784378d40b18ea049ea6191d9ad",
      "98bffba392c84c0387faf9d8816220fc",
      "c9bf31acd43842bf9546f87710746729",
      "68b0b39aa36f464885b6b45dbceca3cd",
      "43fc93da2a284611aa6ca104827f5164",
      "1f6441fabb5c4e5bad49d847fc5c706a",
      "edf885f3641146aeb339454d6815a935",
      "efb20b4e3dd44c6fa6f6892f3cb93a0f",
      "d3d25d36d8064b1a889b2d59da552e3d",
      "ee4a77e315bd481fbd946d43b2f7a0f8",
      "6680fbcf4c8f4974ad0a391000342804",
      "e63ec216feef49b4afbb8226d14265d9",
      "eaa10647f9584889a5da6ddd010672fb",
      "c1583b41a1d64fa4bb2fe546c6d383c7",
      "ecb36f470c47455d8f363dd694ef4b15",
      "ff41515e0a96464fbcaae1df27922434",
      "7c28907c397343f8bd8ff0ad7c19010a",
      "0eae8b98553640db9034eb96040fc6ce",
      "26dbbac8d135413386517cc0855d9745",
      "b0049c909a194896a501044ccbaadf34",
      "1fab2a3c1a654d918de986f6b66756cb",
      "215d5d31e7904e00a1a0063eaf1714ad",
      "3943e894230d4c649a5e4a0de4871a1a",
      "3f1430d677554cd282f44c1638e5c5bf",
      "02be9d9053d24a03837ea8af06454b66",
      "d5b0bfcfd3ef4b55a8a1854804b681ee",
      "788da5da8f684499ba6148ccd876481e",
      "a228841801224211ba4250d8d67bfa5e",
      "8a221f9096a548d29d78780c83630605",
      "5b998d8c86044928a38494be3dfe000c",
      "60ad04f6da4e4571b97427c662ee0fa2",
      "51df6b6fab4c459a9d46d96cc786f23f",
      "c56448d0788c4f0d932c456464eaa7d7",
      "7169dbd95724426a9959f716743e96c1",
      "0dabd15830d34ed9b45598d49c386152",
      "95c6df586e384db783c4622a929fe3ab",
      "d88f8c4cb8704e749c6393fb86dc2853",
      "af26ba9170284b3ab4902f7ba35721d0",
      "4075c7e2d8074dee8580389792cea90b",
      "0b2f75c63217419fbf9dc829bddffa6b",
      "016215216db24453bac3ddbf24c6d309",
      "75acbb8f233f405c86013b3bc919830e",
      "490062e6e7c54d65b3566056111822cb",
      "2180e12e09f04e8883fff9635353c500",
      "f768139bc3674852b792e899c3a22ca7",
      "89c78e3214d14071bcbbba73cf6b6f55",
      "db686e78b79549149ba5b7d9922cdacb",
      "86a7a1644bd9494da1e2e6351783c3cc",
      "5d6781c44964439a9970c3b2007a142d",
      "e17961529df74f9abae2a0008d8947aa",
      "a114a8e2acf74bb382ae31dbe3d540c5",
      "759c26546bbd4e72b7dc2aa38ca518b1",
      "7c76f27a69374f938d567fd16ea8a2af",
      "ea9618e98dc44d45b703a6404f3a0e6e",
      "9ae4c0537c454ecba85f327568f5f0f5",
      "58f7e3fc08554979b40bf7c835f88282",
      "5cb107e40133452a85809f15e480b1df",
      "36b3d8b1761c4f718ae85cf13d6631ce",
      "4bddbf9d16e2484890d05380ad3a4d9d",
      "ab16a8c5115242cc970ba6161852fcc4",
      "df43994bedaa47279b0ffc17e98f3868",
      "297445e8ef7849b7a05fe464e5751f19",
      "de1d2c8ea7134b74acc490f707caee34",
      "f7dc6eb47f33442d9d9427bb00a6c704",
      "6c633fa3d5b9423db1298a8cab9e5c4a",
      "5cdc598ffb11448eb003be2568697b03",
      "da860749ec504800b6a79c3d92ee34a1",
      "1656511ddee045d8b7d784ce75ca5df0",
      "9894e1f52c214f469d80b1cf1c98bc91",
      "46dad5c914144765bae5c9fbe796b37e"
     ]
    },
    "id": "60NGAPgqA9DG",
    "outputId": "b8daf6fe-f03b-441c-9f28-5f863cbfccfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'product-data-from-walmart-usa-with-embeddings' dataset.\n",
      "Ruta de los archivos del dataset: /kaggle/input/product-data-from-walmart-usa-with-embeddings\n",
      "Archivos encontrados: ['walmart-product-with-embeddings-dataset-usa.csv']\n",
      "Columnas disponibles: ['id', 'source_unique_id', 'crawl_timestamp', 'product_url', 'product_name', 'description', 'list_price', 'sale_price', 'brand', 'item_number', 'gtin', 'package_size', 'category', 'postal_code', 'available', 'embedding']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597c7946413d48d2805bb2a0a492fffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa06a9a04c6c4134b3cb8f19c6e92d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32f0448f1fd427cb6a4f5868dba17cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c541243226ca43f8893d225eb09e648e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacaa6af60c64f4b9d342fb1ed444a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c6afe17ec3473d818f201fa16d5cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fc93da2a284611aa6ca104827f5164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff41515e0a96464fbcaae1df27922434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788da5da8f684499ba6148ccd876481e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af26ba9170284b3ab4902f7ba35721d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6781c44964439a9970c3b2007a142d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab16a8c5115242cc970ba6161852fcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Instalaci√≥n e importaci√≥n de librer√≠as\n",
    "# ============================================================\n",
    "!pip install sentence-transformers faiss-cpu gradio kagglehub -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# 2. Cargar dataset desde KaggleHub\n",
    "# ============================================================\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"mauridb/product-data-from-walmart-usa-with-embeddings\")\n",
    "print(\"Ruta de los archivos del dataset:\", path)\n",
    "\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
    "print(\"Archivos encontrados:\", csv_files)\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, csv_files[0]))\n",
    "print(\"Columnas disponibles:\", df.columns.tolist())\n",
    "\n",
    "# ============================================================\n",
    "# 3. Limpieza y selecci√≥n de campos\n",
    "# ============================================================\n",
    "# Combina informaci√≥n textual relevante (nombre + descripci√≥n + categor√≠a + marca)\n",
    "df[\"text\"] = (\n",
    "    df[\"product_name\"].fillna(\"\") + \". \" +\n",
    "    df[\"description\"].fillna(\"\") + \". \" +\n",
    "    df[\"category\"].fillna(\"\") + \". \" +\n",
    "    df[\"brand\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "df = df[df[\"text\"].str.strip() != \"\"]\n",
    "\n",
    "# Muestra un ejemplo\n",
    "df[[\"product_name\", \"category\", \"brand\", \"text\"]].head(2)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Generar embeddings sem√°nticos\n",
    "# ============================================================\n",
    "modelo = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "embeddings = modelo.encode(df[\"text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Crear √≠ndice FAISS\n",
    "# ============================================================\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "# ============================================================\n",
    "# 6. Funci√≥n de b√∫squeda\n",
    "# ============================================================\n",
    "def buscar(query, k=5):\n",
    "    query_vec = modelo.encode([query])\n",
    "    D, I = index.search(np.array(query_vec, dtype=np.float32), k)\n",
    "    resultados = df.iloc[I[0]][[\"product_name\", \"category\", \"brand\", \"description\"]]\n",
    "    resultados[\"distancia\"] = D[0]\n",
    "    return resultados\n",
    "\n",
    "# ============================================================\n",
    "# 7. Interfaz interactiva con Gradio\n",
    "# ============================================================\n",
    "def interfaz(query):\n",
    "    resultados = buscar(query, k=5)\n",
    "    texto = \"\"\n",
    "    for _, fila in resultados.iterrows():\n",
    "        texto += f\"### {fila['product_name']} ({fila['category']})\\n\"\n",
    "        texto += f\"Marca: {fila['brand']}\\n\"\n",
    "        texto += f\"Distancia: {fila['distancia']:.4f}\\n\\n\"\n",
    "        texto += f\"{fila['description']}\\n\\n---\\n\"\n",
    "    return texto\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=interfaz,\n",
    "    inputs=gr.Textbox(label=\"Consulta de producto\", placeholder=\"Ejemplo: snack saludable sin az√∫car\"),\n",
    "    outputs=\"markdown\",\n",
    "    title=\"Buscador Sem√°ntico Walmart\",\n",
    "    description=\"Busca productos de Walmart por significado, combinando nombre, descripci√≥n, categor√≠a y marca.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMAHbRVgB3zQ"
   },
   "source": [
    "## **1. C√≥mo FAISS calcula las similitudes**\n",
    "\n",
    "**FAISS (Facebook AI Similarity Search)** es una biblioteca desarrollada por Meta para realizar b√∫squedas de similitud en grandes vol√∫menes de vectores.\n",
    "Cuando t√∫ generas embeddings con *SentenceTransformer*, cada texto se transforma en un vector de cientos de dimensiones (por ejemplo, 768).\n",
    "FAISS se encarga de comparar esos vectores entre s√≠ de forma eficiente.\n",
    "\n",
    "Veamos c√≥mo ocurre esto paso a paso:\n",
    "\n",
    "1. **Construcci√≥n del √≠ndice**\n",
    "\n",
    "   ```python\n",
    "   index = faiss.IndexFlatL2(dimension)\n",
    "   ```\n",
    "\n",
    "   Aqu√≠ se crea un √≠ndice ‚Äúplano‚Äù (`FlatL2`), que usa la **distancia euclidiana al cuadrado (L2)** para medir la similitud entre vectores.\n",
    "   Cuanto **menor** es la distancia L2 entre dos vectores, m√°s similares son sus significados.\n",
    "\n",
    "2. **Agregado de vectores**\n",
    "\n",
    "   ```python\n",
    "   index.add(np.array(embeddings, dtype=np.float32))\n",
    "   ```\n",
    "\n",
    "   Todos los vectores (uno por producto) se almacenan en el √≠ndice.\n",
    "   FAISS optimiza internamente la estructura para hacer b√∫squedas r√°pidas incluso con miles de vectores.\n",
    "\n",
    "3. **Consulta**\n",
    "\n",
    "   ```python\n",
    "   D, I = index.search(np.array(query_vec, dtype=np.float32), k)\n",
    "   ```\n",
    "\n",
    "   * **`query_vec`**: es el embedding del texto de b√∫squeda.\n",
    "   * **`D`**: es un arreglo con las distancias entre la consulta y los productos m√°s cercanos.\n",
    "   * **`I`**: contiene los √≠ndices (posiciones) de los productos m√°s similares dentro del DataFrame original.\n",
    "\n",
    "   Por ejemplo, si `D[0][0] = 0.15` y `D[0][4] = 0.88`, el primer resultado es mucho m√°s parecido al texto buscado que el quinto.\n",
    "\n",
    "4. **Interpretaci√≥n**\n",
    "   En un √≠ndice L2, la similitud se basa en **distancia m√≠nima**:\n",
    "\n",
    "   * Distancia 0: vectores id√©nticos.\n",
    "   * Distancia peque√±a: textos muy relacionados.\n",
    "   * Distancia grande: textos sin relaci√≥n sem√°ntica.\n",
    "\n",
    "Si quisieras usar similitud **coseno** en lugar de L2 (m√°s com√∫n en procesamiento de texto), podr√≠as normalizar los vectores antes de a√±adirlos al √≠ndice:\n",
    "\n",
    "```python\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "index = faiss.IndexFlatIP(dimension)  # IP = Inner Product\n",
    "```\n",
    "\n",
    "De este modo, FAISS buscar√≠a los vectores con el **producto interno m√°s alto**, equivalente a mayor similitud coseno.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. C√≥mo usar los embeddings ya incluidos en el dataset**\n",
    "\n",
    "El dataset de Walmart que descargaste **ya contiene una columna llamada `embedding`**, que parece guardar los vectores precomputados.\n",
    "Esto significa que **no necesitas volver a generar embeddings** con `SentenceTransformer`, lo que puede ahorrar tiempo y recursos.\n",
    "\n",
    "Sin embargo, esos embeddings vienen almacenados como texto (por ejemplo: `\"[0.123, -0.452, 0.876, ...]\"`), por lo que primero hay que convertirlos a arreglos num√©ricos de `numpy`.\n",
    "\n",
    "Aqu√≠ tienes c√≥mo hacerlo:\n",
    "\n",
    "```python\n",
    "import ast\n",
    "\n",
    "# Convierte los embeddings desde texto a lista num√©rica\n",
    "df[\"embedding\"] = df[\"embedding\"].apply(ast.literal_eval)\n",
    "\n",
    "# Crea una matriz de numpy con los vectores\n",
    "embeddings = np.array(df[\"embedding\"].tolist()).astype(\"float32\")\n",
    "\n",
    "# Crea el √≠ndice FAISS directamente con ellos\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Funci√≥n de b√∫squeda adaptada\n",
    "def buscar(query, k=5):\n",
    "    query_vec = modelo.encode([query])  # a√∫n necesitas el modelo para consultas nuevas\n",
    "    D, I = index.search(np.array(query_vec, dtype=np.float32), k)\n",
    "    resultados = df.iloc[I[0]][[\"product_name\", \"category\", \"brand\", \"description\"]]\n",
    "    resultados[\"distancia\"] = D[0]\n",
    "    return resultados\n",
    "```\n",
    "\n",
    "En este caso:\n",
    "\n",
    "* Usas los embeddings del dataset (ya calculados para cada producto).\n",
    "* Solo generas un embedding nuevo cuando el usuario realiza una consulta.\n",
    "* El tiempo de procesamiento se reduce considerablemente.\n",
    "\n",
    "---\n",
    "\n",
    "## **Resumen conceptual**\n",
    "\n",
    "| Proceso                                        | Qu√© hace                                                                     | Cu√°ndo usarlo                                                         |\n",
    "| ---------------------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| **Generar embeddings con SentenceTransformer** | Convierte texto en vectores sem√°nticos nuevos.                               | Si el dataset no tiene embeddings o si quieres usar tu propio modelo. |\n",
    "| **Usar embeddings preexistentes**              | Carga los vectores ya calculados en el dataset.                              | Si el dataset ya incluye una columna `embedding`.                     |\n",
    "| **√çndice FAISS (L2 o coseno)**                 | Permite buscar r√°pidamente los textos m√°s similares en el espacio vectorial. | Siempre necesario para la b√∫squeda sem√°ntica eficiente.               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZDbGSroB-M7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from google.colab import files\n",
    "\n",
    "# ============================================================\n",
    "# 1. Cargar dataset desde KaggleHub (si a√∫n no est√° cargado)\n",
    "# ============================================================\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"mauridb/product-data-from-walmart-usa-with-embeddings\")\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
    "df = pd.read_csv(os.path.join(path, csv_files[0]))\n",
    "\n",
    "# ============================================================\n",
    "# 2. Convertir embeddings desde texto a listas num√©ricas\n",
    "# ============================================================\n",
    "# Convierte la columna 'embedding' (tipo str) a lista de floats\n",
    "df[\"embedding\"] = df[\"embedding\"].apply(ast.literal_eval)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Crear el archivo vectors.tsv\n",
    "# ============================================================\n",
    "# Cada fila del TSV ser√° un vector de embedding\n",
    "vectors = np.array(df[\"embedding\"].tolist())\n",
    "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Crear el archivo metadata.tsv\n",
    "# ============================================================\n",
    "# Incluye campos descriptivos para identificar los puntos\n",
    "metadata = df[[\"product_name\", \"category\", \"brand\", \"sale_price\"]].fillna(\"\")\n",
    "metadata.to_csv(\"metadata.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Descargar los archivos para subirlos al TensorFlow Projector\n",
    "# ============================================================\n",
    "files.download(\"vectors.tsv\")\n",
    "files.download(\"metadata.tsv\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNxqjvY4mRmWxDkEkUPs7X8",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
